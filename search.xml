<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[论文:Globally Normalized Transition-Based Neural Networks]]></title>
    <url>%2F2018%2F11%2F15%2F%E8%AE%BA%E6%96%87-Globally-Normalized-Transition-Based-Neural-Networks%2F</url>
    <content type="text"><![CDATA[SyntaxNet :Globally Normalized Transition-Based Neural NetworksDaniel Andor, Chris Alberti, David Weiss, Aliaksei Severyn et.alGoogle Inc Abstract我们设计了一个全局正则化的基于转移的神经网络模型(a globally normalized transition-based neural network)，在POS,依赖解析，语句压缩达到了最好的效果。我们的模型是一个在特定trainsition任务上简单的前向传播神经网络，与其它模型相比，准确率更高。我们讨论了global normalization及local normalization：一个重要的概念是标签的偏差意味着globally normalized 模型比locally normalized模型更严格的表达。 IntroductionNN在NLP领域应用广泛，LSTM在POS,语法解析，语义角色标注应用广泛。一个观点是因为循环神经网络才得到这样的效果 我们验证了使用仅globally normalized，精度也能达到甚至超过使用RNN的模型。详见第二节。我们不使用任何循环结构，但用集束搜索验证多个假设，并使用条件随机场(CRF)目标引入globally normalized，以克服locally normalized所遇到的标签偏差问题(???读不懂)。由于我们使用集束推断，我们通过对集束中的元素求和来近似分割函数，并使用早期更新（Collins和Roark，2004; Zhou等，2015）。 我们基于该近似全局归一化来计算梯度，并基于CRF损失对所有神经网络参数执行完全反向传播训练。 章节3重新回顾了下标签偏差问题，说明globally normalized 模型比local normalized模型能更严格的表达。我们的模型在词性标注POS，依赖解析和语句压缩上取得最好的精度，特别是华尔街日报的依赖解析达到历史最好94.61%。 章节5中，我们模型也优于以前用于基于神经网络转换的解析的结构化训练方法。为了在实践过程中进一步阐述标签偏差问题，我们提供了一个语句压缩的例子，其中local 模型几乎完全失败。然后我们证明了没有任何lookahead features的globally normalized模型几乎与我们的最佳模型一样准确。 最后，我们提供了一个名为SyntaxNet的方法的开源实现，我们已将其集成到流行的TensorFlow框架中。 我们还提供了一个预先训练的，最先进的英语依赖解析器，名为“Parsey McParseface”，我们在速度，简单性和准确性方面进行了调整。 2 Model我们的模型是增量式基于转移的解析器。将它应用到不同的任务上只需要调整transition system和 input feature。 2.1 Transition system对于输入 $x$，通常是一个语句，我们定义： 状态集合$S(x)$ 特定的开始符号 $S^{\dagger} \in S(x)$ 允许的决策集合 $A(s,x)$, 所有的$s \in S(x)$ 转移函数 $t(s,d,x)$, 对任一决策$d \in A(s,x)$返回一个新的状态$s^\prime$ 我们会使用函数 $\rho(s,d,x;\theta)$ 来计算输入$x$在状态$s$做决策$d$的得分。向量 $\theta$ 包含模型的所有参数，我们认为 $\rho(s,d,x;\theta)$ 和 $\theta$ 是不同的表示。 本节中，我们省略$x$，函数记为 $S,A(s),t(s,d),\rho(s,d;\theta)$。 在整个工作中，我们使用transition system，相同输入$x$的完整结构，具有相同数量$n(x)$(或简单记为n)的决策。例如，在依赖解析中，arc-standard 和 arc-eager transition system 都是如此，对于长度为$m$的语句输入$x$，完整解析的决策为$n(x) = 2 \times m$。完整结构(complete structure) 是决策/状态序列 $(s1,d_1)…(s_n,d_n)$, $s_1= s^{\dagger}, d_i \in S(s_i)$, 每个$i = 1…n$, $s{i+1} = t(si,d_i)$。我们用 $d{1:j}$ 来表示决策序列$d_1…d_j$。 我们认为决策序列 $d{i:j}$ 和状态 $s_j$是一对一映射：也就是说，我们基本假设一个状态编码了整个决策历史。因此每个序列可以通过从 $S^{\dagger}$ 开始的唯一的决策序列得到。决策序列 $d{1:j-1}$ 和状态可替换表示，我们定义 $\rho(d{1:j-1},d;\theta)$ 与 $rho(s,d;\theta)$等同，其中s是 $d{1:j-1}$ 到达的状态。 得分函数的定义有很多种，我们通过前向传播神经网络来定义： \rho(s,d;\theta)=\phi(s;\theta^{(l)}) \cdot \theta^{(d)}.$\theta^{(l)}$ 是神经网络出去最后一层的所有参数。$\theta^{(d)}$ 是对决策$d$的最后一层参数。 $\phi(s;\theta^{(l)})$ 表示神经网络在参数 $\theta^{(l)}$ 计算得到的状态 $s$。注意，在参数 $\theta^{(d)}$下得分是线性的。我们之后会解释 softmax-style normalization 是如何应用在global和local级的。 2.2 Global vs. Local Normalization在Chen&amp;Manning(2014)的贪婪式神经网络解析中，在上下文 $d_{1:j-1}$ 下决策 $d_j$ 的条件概率分布定义如下： p(d_j | d_{1:j-1;\theta}) = \frac{\exp \rho(d_{1:j-1}, d_j; \theta)}{Z_L(d_{1:j-1}; \theta)} \tag{1}其中： Z_L(d_{1:j-1}; \theta) = \sum_{d^\prime \in A(d_{1:j-1})} \exp \rho(d_{1:j-1},d^\prime; \theta)每一个 $ZL(d{1:j-1}; \theta)$是一个 local normalization 项。决策序列 $d_{1:n}$ 的概率为： p_L(d^{1:n} = \prod_{j=1}^n p(d_j | d_{1:j-1; \theta})\\ =\frac{\exp \sum_{j=1}^n \rho(d_{1:j-1, d_j; \theta})}{\prod_{n=1}^{n}Z_L(d_{1:j-1}; \theta)}. \tag{2}集束搜索尝试找到Eq.(2)的最大化。集束搜索终得附加分是对每个决策使用logsoftmax，$\ln p(dj | d{1:j-1}; \theta)$,而不是原始分数 $\rho(d_{1:j-1}, d_j; \theta)$。 相反，条件随机场(CRF)定义的 $pG(d{1:n})$ 如下： p_G(d_{1:n}) = \frac{\exp \sum_{j=1}^n \rho(d_{1:j-1}, d_j; \theta)}{Z_G(\theta)} \tag{3}其中， Z_G(\theta) = \sum_{d_{1:n}^\prime \in D_n} \exp \sum_{j=1}^n \rho(d_{1:j-1}^\prime, d_j^\prime; \theta)$D_n$是所有的长度为n的有效决策序列集合， $Z_G(\theta)$是global normalization 项。现在推断问题成为找到： \text{argmax}_{d_{1:n} \in D_n} = \text{argmax}_{d_{1:n}\in D_n} \sum_{j=1}^n \rho(d_{1:j-1}, d_j; \theta).可以再次使用集束搜索来找到近似argmax。 2.3 Training训练数据是由输入 $x$ 和 gold decision 序列 $d_{1:n}^*$ 组合而成。我们使用随机梯度下降和对数似然估计(negative log-likehood)函数。在 locally normalized model中，negative log-likehood 函数为： L_{local}(d_{1:n}^*;\theta) = -\ln p_L(d_{1:n}^*;\theta) = \\ -\sum_{j=1}^n \rho(d_{1:n}^*, d_j^*; \theta) + \sum_{j=1}^n\ln Z_L(d_{1:n}^*; \theta) \tag{4}而globally normalized model 的似然估计函数为： L_{global}(d_{1:n}^*;\theta) = -\ln p_G(d_{1:n}^*;\theta) = \\ -\sum_{j=1}^n \rho(d_{1:n}^*, d_j^*; \theta) + \sum_{j=1}^n\ln Z_G(d_{1:n}^*; \theta) \tag{5}locally normalized 的一个显著优势是公式4中 $Z_L$及其导数计算快速有效。而Eq.5中 $Z_G$ 项在很多情况下是难以处理的。 为了使globally normalized 模型更易学习，我们使用集束搜索和early updates。随着训练序列解码，我们记录集束中的gold path，如果gold path落在 $j$ 布集束之外，将对以下目标进行随机梯度步骤： L_{global-beam}(d_{1:n}^*:\theta) = \\ -\sum_{i=1}^j \rho(d_{1:i-1}^*;\theta) + \ln \sum_{d_{1:j} \in \mit{B_j} } \exp \sum_{i=1}^j \rho(d_{1:n}^\prime, d_i^\prime; \theta) . \tag{6}其中， $\mit{B}j$ 是 $j$ 步集束的所有路径, 前缀 $d{i:j}^*$。可以直接计算Eq.6 中loss的梯度，并反向传播。如果gold path 在整个解码过程中保留，则使用解码结束后的集束 $\mit{b_n}$执行梯度步骤。 3 The Label Bias Problem直观来讲，我们希望模型能够在发现错误后，能够修改之前的决策错误。乍一看，使用集束搜索或其它确定搜索结合的locally normalized模型能够修改之前的决策。但是label bias问题(see Bottou (1991), Collins (1999) pages 222-226, Lafferty et al. (2001), Bottou and LeCun (2005), Smith and Johnson (2007))说明其在这方面能力非常弱。 本节通过证明全局规范化模型比局部规范化模型更具表现力，证明了标签偏差问题的正式观点。 Global Models can be Strictly More Expressive than Local Models来考虑将输入序列 $x{1:n}$ 映射成决策序列 $d{1:n}$任务中的 tagging problem。首先，考虑到locally normalized 模型， 在对决策 $di$ 评分时，我们将限制评分函数取到前 $i$ 个输入符号 $x{1:i}$。 评分函数 $rho$ 可以是元组 $\langle d{1:i-1}, d_i, x{1:i}\rangle$ 的其他任意函数: p_L(d_{1:n} | x_{1:n}) = \prod_{i=1}^n p_L(d_i|d_{1:i-1}, x_{1:i}) \\ = \frac{\exp \sum_{i=1}^n \rho(d_{1:i-1}, d_i, x_{1:i})}{\prod_{i=1}^n Z_L(d_{1:i-1}, x_{1:i})}其次，考虑 globally normalized模型： p_G(d_{1:n} | x_{1:n}) = \frac{\exp \sum_{i=1}^n \rho(d_{1:i-1}, d_i, x_{1:i}) }{Z_G(x_{1:n})}这个模型同样的得分函数，在对决策 $d_i$ 评分时，限制于前 $i$ 个输入。 定义 $\mit{PL}$ 为locallly normalized 模型下得分 $\rho$ 所有可能的分布集合 $P_L(d{1:n} | x{1:n})$。同理，可以定义 globally normalized 模型$P_G$。这里的“分布”是一个从 $(x{1:n}, d{1:n})$ 到概率 $p(d{1:n}|x_{1:n}$。我们的主要结果如下(证明可参考论文)。 4 Experiments我们在POS，依赖解析，语句压缩三个任务上进行实验。 4.1 POS数据集： the English Wall Street Journal (WSJ) part of the Penn Treebank the English “Treebank Union” multi-domain corpus containing data from the OntoNotes corpus version 5 the CoNLL ’09 multi-lingual shared task Model ConﬁgurationResult 4.2 依赖解析数据集与POS任务数据集一样，此外，使用WSJ的标准依赖切分。Model Conﬁguration与 Chen and Manning (2014)一致。Result 4.3 语句压缩数据集Filippova(2015)数据集。Model Conﬁguration与transition system相似，将左右替换成keep和drop。Result 5 Discussion略 6 Conclusion我们提出了一种简单但功能强大的模型体系结构，可为POS标记，依赖性解析和句子压缩生成最好的结果。 我们的模型结合了 transition-based 的算法的灵活性和神经网络的建模能力。 我们的研究结果表明，没有循环的前馈网络在通过全局规范化训练时可以胜过LSTM等RNN模型。 我们进一步支持我们的实证结果，证明全局标准化有助于模型克服局部标准化模型所遭受的标签偏差问题。]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>cs224n</tag>
        <tag>nlp</tag>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文:A Fast and Accurate Dependency Parserusing Neural Networks]]></title>
    <url>%2F2018%2F11%2F13%2F%E8%AE%BA%E6%96%87-A-Fast-and-Accurate-Dependency-Parserusing-Neural-Networks%2F</url>
    <content type="text"><![CDATA[A Fast and Accurate Dependency Parser using Neural NetworksDanqi Chen, Christopher D. ManningStanford University Abstract现在几乎所有的依赖解析器(dependency parsers)都是基于数百万个稀疏指示器特征(sparse indicator feature)进行分类。这些特征泛化能力差，计算成本高。本文提出了一种新的贪婪式(greedy),基于转移(trasition-based)依赖解析器(dependency parser)来实现神经网络学习。由于分类器学习和使用少量的dense feature，所以它运行快，不论是在中文还是英文上有LAS或UAS提高了2%。具体来说，我们的解析器能在92%的UAS数据上每秒处理1000个句子。 Introduction现在，基于特征的判别式依赖解析器(feature-based discriminative dependency parser)(K¨ubler et al., 2009)。应用中基于转换的及其子类解析器都比较快速。但这些解析器仍不完美。首先，从统计学角度来讲，他们使用数百万并不是很好的特征权重，虽然整体上词汇特征和高级交互特征在提升算法，但没有足够数据来给这些权重正确赋值。其次，所有的解析器都需要手工设计特征模板，这需要专业性，通常并不完整。再而，许多特征模板在研究很少的问题：现在解析器，最大的耗时不是算法，而是特征提取。Bohnet说他的算法虽然有效，但99%的时候都在特征提取。 受词向量成功的启发(POS任务)，我们想使用dense feature来解决问题。低维，密集的特征是不错的良好的开始。 然而，如何对配置信息中所有有用信息进行编码，如何建模基于密集表示的高层特征都是挑战。我们训练了一个神经网络分类器，来在trainsition-based 依赖解析器中做解析决策。神经网络能生成词向量，POS，和依赖标签。我们仅使用200个特征在中文和英文的两个不同雨来任务中取得快速而准确的效果。本文贡献： 展示解析任务中学习到密集特征(dense representation)的效果。 提出了新的神经网络结构，速度与精度兼有 介绍一种新的， 能更好得到高层交互特征的激活函数 2 Transition-based Dependency Parsing基于转移的依赖解析旨在预测从初始配置到终端配置的转移序列，结果为依赖树。其效果如图所示：在本文中，我们使用贪婪解析，即使用分类器在从配置提取的他反正基础上对transition进行预测。这类解析器很要意思，他快速，虽有由于错误传播，准确率略低于基于搜索(search-based)的解析器. 本文采用arc-standard系统(Nivre 2004)。 configuration 的含义；$c = (s, b, A)$,分别是Stack, Buffer, Dependency Arc。初始化时候，$s = [ROOT], b = [w_1,w_2…w_n],A = \emptyset$。三个操作定义(可参考之前博文)： LEFT-ARC(l):添加边$s1 \rightarrow s2$及label (l)，并移除$s2$。约束 $|s&gt;2|$ RIGHT-ARC(l):添加边$s1 \leftarrow s2$,并将s1出栈。约束 $|s&gt;2|$ SHIFT将元素进栈。约束 $|b|&gt;1$ Transitions共有 $|T|=2N_l+1$个。图一解释了Trasition序列例子，从初始配置到终端配置。 贪婪解析的本质目标是在给定configuration下，从$T$预测正确的transition。 从一个configuration可以得到以下信息：1. 所有单词及其词性POS标签 2. 每个单词的头及标签 3.单词在栈/缓冲区的位置，不管是否已出栈。 传统特征模板的弊端： 稀疏。特征稀疏，尤其是词汇化特征稀疏是NLP任务常见问题。我们对English Penn Treebank(表1)进行了特征分析。结果如表2.结果说明：1）词汇特征是必不可少的。2）单词对很重要，三词组也很重要。 不完整。不完整性是现有特征模板的不可避免的问题。因为设计手工处理，无法包含每个有用单词对。 计算成本高。 indicator features的特征抽取代价很高。我们必须连接一些单词，POS标签，边标签来生成特征字符串，并在庞大的特征中来寻找。我们的实验中，95%的时间是特征计算。 到目前为止，我们已经讨论了基于转换的依赖解析的初步和稀疏指标特征的现有问题。 在接下来的部分中，我们将详细阐述我们的神经网络模型，以便通过实验评估来证明其效率。 3 Neural Network Based Parser本节介绍神经网络模型和其细节，包括训练，加速解析。 3.1 Model图2描述了网络结构，首先，词向量是一个$d$维向量，用$e_i^w \in \mathbb{R}^d$表示,整个嵌入矩阵用 $E^w \in \mathbb{R}^{d \times N_w}$ 表示, 其中 $N_w$ 为字典大小。同时我们还将POS标签和和边标签影射成$d$维度向量，$e_i^t,e_j^l$ 表示第$i$个POS标签，第$j$个标签。相应的，$E^t \in \mathbb{R}^{d\times N_t}$ 表示全部的POS标签，$N_t$ 为标签的数量。同理$E^l \in \mathbb{R}^{d\times N_l}$。 我们根据每种类型信息（字，POS或标签）的堆栈/缓冲区位置选择一组元素，这可能对我们的预测有效，分别用 $S^w, S^t, S^l$表示。如图2中，$S^t = {lc1(s2).t,s2.t,rc1(s2).t,s1.t}$ , 我们会依次抽取 $PRP, VBZ, NULL, JJ$。我们使用NULL来表示不存在元素。 我们建立了单隐层标准神经网络，我们从$S^w, S^t, S^l$插曲的元素将会输入到神经网络，用 $nw, n_t, n_l$表示每种类型元素的数量。我们将 $x_w = [ e{w1}^w; e{w2}^w;…e{wnw}^w ]$添加到输入层， 其中 $S^w = {w_1,…,w{n_w}}$。同样，我们添加$x^t$ , $x^l$到输入层。 隐层使用立方激活函数(cube activation function): h = (W_1^wx^w + W_1^tx^t + w_1^lx^l + b1)^3$W_1^w \in \mathbb{R}^{d_h \times (d \cdot n_w)}$ , $W_1^t \in \mathbb{R}^{d_h \times (d\cdot n_t)}$ , $W_1^w \in \mathbb{R}^{d_h \times (d \cdot n_l)}$ , $b1$是偏置项。 POS and label embeddings据我们所知，这是首次尝试引入POS标签和圆弧标签嵌入而不是离散表示。尽管POS标签 $\mathbb{P} = {\text{NN, NNP, NNS, DT, JJ…}}$(英语)和边标签 $\mathbb{L} = {\text{amod,tmod,nsubj,…}}$(英语标准依赖)是相对比较小的离散集合，但它们像单词一样，仍然包含很多语义信息。比如NN(singularnoun)比DT(DETERMINER)和NNS(pluralnoun)更接近。我们想要有效抽取更加密集的表示。 Cube activation functioncube $g(x) = x^3$ 来替代sigmoid函数。cube函数能对三个来自不同嵌入维度的$x_ix_jx_k$建模，能更好的适用于依赖解析。Cube函数仍需要理论分析。 The choice of $S^w, S^t, S^l$根据(Zhang and Nivre, 2011)工作，我们选择rich set of elements。 细节上来说，$S^w$包含 $n_w$ = 18个元素：（1）stack及buffer的top 3元素：$s1,s2,s3,b1,b2,b3$;（2）stack top 2元素的第一和第二最可能的左/右孩子：$lc_1(s_i),rc_1(s_i),lc_2(s_i),rc_2(s_i), i=1,2$. （3）stack top 2元素的最可能的左/右元素的左/右元素。 POS标签数据与之对应(18)。边标签数据与之相应$S_l(n_l=12)$。我们的解析器胜在可以很简单的添加一组特征，省去手工繁琐步骤。 3.2 Training我们首先根据训练语句创建样本 ${(ci,t_i)}{i=1}^m$,$c_i$是配置Configuration, $t_i$是预测transition。 模型采用交叉熵损失函数，并使用l2正则化： L(\theta) = - \sum_i \log p_{t_i} + \frac{\lambda}{2}||\theta||^2$\theta$是所有的参数${W_1^w,W_1^t,W_1^l,b1,W_2,E_w,E_t,E_l}$,最后使用softmax来做预测。 对于参数的初始化，我们使用预训练词嵌入l来初始化$E^w$，使用(-0.01,0.01)来初始化$E^t$, $E^l$。英语的预训练词嵌入来自于(Collobert et al., 2011)(#dictionary = 130,000, coverage = 72.7%)，和我们的基于维基的50维度word2vec词嵌入 (Mikolov et al., 2013) ，以及中文语料库的Gigaword (#dictionary =285,791, coverage = 79.0%)。我们也做了随机初始化$E^w$对比试验，详见Section4。模型使用反向传播算法来训练嵌入。 模型使用 mini-batch AdaGrad作为优化器，并使用Dropout(0.5)技术。在开发集上上无标签成就分数(unlabeled attachment score)最高的参数模型作为最终选择。 3.3 Parsing在解析过程中我们选择贪婪解码。在每一步，我们从当前配置Configuration $c$中抽取所有对应的单词，POS和标签嵌入，然后计算$h(c) \in \mathbb{R}^{dh}$，选择最高分 $t=\text{arg max}{t \text{ is feasible}}W_2(t,\cdot)h(c)$，然后执行 $c \rightarrow t(c)$。 与indicator features相比，我们的解析不需要计算连接特征和在巨大特征表中检索，因此特征生成时间大幅减少。其包含大量矩阵加法和乘法操作。为了进一步提高速度，我们采用pre-computation技巧。对 $S^w$，我们预先计算每个位置的最常见10000个单词。因此，隐层计算只需要检索，然后添加 $d_h$维向量。同样，可以计算POS和边标签每个位置的10000个单词。我们只在神经网络解析器中使用这个优化方法，能加速8-10倍。 4 Experiments4.1 Details数据集：English Penn Treebank(PTB) 和 Chinese Penn Treebank(CTB)。图三是三个数据集的统计情况。 4.2 Results超参数设置：嵌入维度$d$=50，隐层大小$h$=200,正则化率 $\lambda = 10^{-8}$,AdaGrad学习率 $\alpha = 0.01$。 同时，我们自己实现了arc-eager算法和arc-standard算法作为对比实验。此外，还与最新的两个解析器进行比较，MaltPaser - 基于转移的贪婪式依赖解析(a greedy transition-based dependency parser)(Nivre et al., 2006)， MSTParser - 基于图的先序解析器(a first-order graph-based parser)(McDonald 2006)。 评估参数：LAS(labeled attachment score) 和 UAS(unlabeled attachment score)。测试环境i7 2.7Ghz 16G RAM 在三个数据集的结果：准确率基本第一梯度，速度基本碾压。 4.3 Effects of Parser ComponentsCube activation function简而言之，Cube比其它激活函数激活高0.8~1.2% Initialization of pre-trained word embeddings预训练在PTB上有0.7%的提升，CBT上1.7%的提升 POS tag and arc label embeddings使用三者结合准确率最高。 4.4 Model Analysis最后，我们研究了参数学习到了什么，特征捕获了什么。 What do $E^t$, $E^l$ capture?使用t-SNE算法对特征进行可视化，如图5。这些嵌入有效地展示了POS标签或弧标签之间的相似性。POS中JJ,JJR,JJS非常相近。acomp,ccomp,xcomp分到了一起。我们有理由相信，POS嵌入对NLP其他任务也会有帮助。 What do $W_1^w,W_1^t,W_1^l$ capture?在了解$E^t$,$E^l$像$E^w$一样能学习到语义信息后，我们想研究每个特征在隐藏中学习到什么。 我们想知道隐层大小$h=200$是否学习到足够的信息。对每个隐层单元$k$，将其权重reshape成 $d \times n_t, d \times n_w, d \times n_l$。这样每个元素和词嵌入矩阵是保持一致的。 我们选取绝对值大于0.2的权重，然后对每个特征可视化它们。图6是三个采样特征，可以看到很有趣的现象： 不同的特征权重分布式多样的。 然而，大多数判别权重来自$W_1^t$（图6中的中间区域），并且这进一步证明了POS标记在依赖性解析中的重要性。 我们仔细研究了$h=200$个特征发现，它们编码了不同的信息。在图6中三个采样点，最大的权重是由以下确定的： Feature 1:$s_1.t, s_2.t, lc(s_1).t$ Feature 2:$rc(s1).t, s1.t, b1.t$ Feature 3:s_1.t, s1.w, lc(s1).t, lc(s1).l通过在indicator feature 实验上观察，这些特征非常合理。我们的模型自动识别最有用的信息来进行预测，而不用手工创建。 我们可以轻松提取三个以上元素特征，包括indicator feature没有的特征。 5 Related Work6 Conclusion我们使用神经网络提出了一种新颖的依赖解析器。 实验评估表明，我们的解析器在精度和速度方面都优于使用sparse indicator features 的其他贪心解析器。 这是通过将所有单词，POS标签和圆弧标签表示为密集向量，并通过新颖的立方体激活函数对其交互进行建模来实现的。 我们的模型仅依赖于密集的特征，并且能够自动学习最有用的特征连接以进行预测。接下来工作是结合神经网络分类器和search-based 模型来进一步提高精度。当然，网络模型还有提升的空间。]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>cs224n</tag>
        <tag>nlp</tag>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文:Incrementality in Deterministic Dependency Parsing]]></title>
    <url>%2F2018%2F11%2F08%2F%E8%AE%BA%E6%96%87-Incrementality-in-Deterministic-Dependency-Parsing%2F</url>
    <content type="text"><![CDATA[Incrementality in Deterministic Dependency ParsingJoakim NivreVaxjo University Abstract确定性依赖解析(Deterministic dependency parsing)是一个鲁棒和高效的非限制性自然语言文本句法解析方法。本文分析了其增量处理的可能性，并得出结论：在此框架内无法严格实现增量。但是我们还证明，通过选择最优解析算法，可以最小化需要非增量处理结构的数量。这一说法得到了实验证据的证实，该证据表明，当在瑞典文本的随机样本上进行测试时，该算法实现了对输入的68.9％的增量解析。 当限于解析器接受的句子时，增量程度增加到87.9％。 Introduction增量解析被提倡是出于至少两个不同的原因。第一从实用性上讲，语音识别等实时任务需要对当前输入进行不断的更新的分析。第二从理论上来说，增量解析将解析和认知建模(congnitive modeling)联系在一起。然而，由于不同的原因，目前大多数最先进的解析方法都不遵循增量性原则。尝试完全消除输入歧义的解析器 - 即完全解析 - 通常首先使用某种动态编程算法来派生包解析林(packed parse forest)，然后应用概率自上而下模型以选择最可能的分析(Collins, 1997; Charniak, 2000)。由于第一步是基本不确定的，这似乎至少在严格意义上排除了增量性。与之相反，只对输入消除部分歧义的解析器-即部分解析(partial parsing)-通常是确定的，通过一次输入构建最终分析(Abney, 1991; Daelemans et al., 1999)。但由于它们通常会输出一系列未连接的短语或块，因此不能满足增量性的限制。最近提出的确定性依赖解析(Deterministic dependency parsing)作为用于语法分析非受限自然语言文本的方法，具有鲁棒性和高效性(Yamada and Matsumoto, 2003; Nivre, 2003)。在某些方面，这种方法可以看作是传统的完整解析和部分解析之间的折衷。本质上，它是一种全解析，其目标是构建一个对输入字符的完整的语法分析，而不是仅仅是确定主要成分。但它和部分解析类似，是具有鲁棒，高效和确定性的。总而言之，这些属性似乎是依赖解析适应于增量处理，尽管有些实现并不满足这些约束。例如，Yamada和Matsumoto（2003）使用多通道自下而上算法，结合支持向量机，其方式不会导致增量处理。在本文中，我们分析了确定性依赖解析中增量性的约束，并认为严格的增量是不可实现的。 然后，我们分析了Nivre（2003）中提出的算法，并且表明，鉴于先前的结果，该算法从增量性的角度来看是最优的。 最后，我们实验性地评估了算法在实际解析中实现的增量程度。 2 Dependency Parsing在依赖结构中，每个word token是依赖于最多一个的其它word token，通常称之为它的head或regent。也就是说，依赖结构可以使用有向图(directed graph)来表示。节点node表示word token，边arcs表示依赖关系。此外，边arcs可以标记特定依赖类型。图1为瑞典语句的标记依赖图。在下文中，我们将注意力限制在未标记的依赖图上，即没有标记弧的图，但结果也将适用于标记的依赖图。 我们也将自己局限于投影依赖图（Mel’cuk，1988）。 在形式上，我们通过以下方式定义这些结构： 一个依赖图的单词集合$W = w_1…w_n$,边集合$D = (W, A)$。A是由边的集合组成，$(w_i, w_j), (w_i, w_j \in W)$。$w_i &lt; w_j$表示$w_i$先于$w_j$在字符串$W$出现。$w_i \rightarrow w_j$ 表示一条边，$\rightarrow^$ 表示弧关系的重新闭合和传递闭合。 $\leftrightarrow$ 和表示 $\leftrightarrow^$ 对应的无向关系。 依赖图 $D = {W, A}$ 的约束如图2。 将字符串$W = w_1…w_n$在满足约束的条件下映射到依赖图的任务，我们称之为依赖解析(dependency parsing)。更多的细节参考Nivre (2003)。 3 Incrementtality in Dependency Parsing在定义完依赖图后o，我们可以考虑在多大程度上可以逐步构件图。从最严格的意义上讲，我们采用的增量表示，在解析过程中的任何一个时候，都存在一个连接结构，表示目前为止，对输入所做的分析。对我们的依赖图而言，是说在解析过程中图始终是连接的。我们将提高在一分钟内的精度，但首先讨论下增量性(incrementality)和确定性(determinism)间的关系。 至少在从不撤销之前做出的决定这一方面讲，增量性似乎本身并不代表确定性。 因此，涉及回溯的解析方法可以是递增的，只要回溯以这样的方式实现，即我们总是可以维持表示直到回溯点处理的输入的单个结构。 在依赖解析的上下文中，一个典型的例子是Kromann（Kromann，2002）提出的解析方法，它将启发式搜索与不同的修复机制相结合。 在本文中，我们将把注意力限制在依赖性解析的确定性方法上，因为我们认为在更严格的框架内更容易确定基本约束。 我们将以一种方式形式化确定性依赖解析，该方式受传统的基于无上下文语法的shift-reduce解析的启发，使用输入令牌的缓冲区和用于存储先前处理的输入的栈。 但是，由于依赖性解析中不涉及非终结符号，我们还需要维护在处理期间构造的依赖图的表示。 我们使用 $\langle S,I,A \rangle$ 表示解析器配置。$S$是由一个列表表示的栈，$I$ 是输入token列表。$A$ 是依赖图的当前边关系。(由于依赖图的节点由输入字符串给出，因此只需要明确表示弧关系)。给定输入字符串$W$后， 解析器初始化为 $\langle \textbf{nil}, W, \emptyset \rangle$，并在达到 $\langle S, \textbf{nil},A \rangle$条件时终止。如果在结束时图$D=(W,A)$是结构良好的，则接收accept字符串$W$,否则拒绝reject. 为了理解依赖性解析中增量性的约束，我们将首先考虑最直接的解析策略，即从左到右的自下而上解析，在这种情况下，它基本上等同于使用上下文的shift-reduce解析。 乔姆斯基正常形式的自由语法。 解析器以转换系统的形式定义，如图3所示（其中$w_i$和$w_j$是任意字标记）： Left-Reduce转换是结合了栈里的两个token，$w_i$和$w_j$，通过左向相连：$w_j \rightarrow w_i$，头是$w_j$ Right-Reduce转换是结合了栈里的两个token，$wi$和$w_j$，通过右向相连：$w \rightarrow wj$，头是$w$ Shift操作是将下一个token进栈。 Left-Reduce和Right-Reduce transitions的约束是保证满足单头Single head条件。Shift操作的约束是列表非空。 可以看到，由于多个transitions能应用相同的配置，整个transition system是不确定的。因此，为了得到具有确定性的解析器，我们需要引入一种解决过渡冲突的机制。不管使用哪个机制，在给定长度为n的字符串下，要保证解析器能在2n transitions内完成。此外，保证解析器生成非循环和映射的依赖图（并且满足单头约束）。 这意味着当且仅当连接时，终止时给出的依赖图是格式良好的。 我们现代可以定义这个框架中解析器的增量的含义。理想情况下，我们希望图表 $\langle W-I，A\rangle$始终连接。 然而，考虑到Left-Reduce和Right-Reduce的定义，不可能在没有将其移动到堆栈的情况下连接新单词，因此似乎更合理的条件是堆栈的大小不应超过2。 通过这种方式，我们要求每个单词一旦被移动到堆栈上就被附加在依赖图中的某处。 我们现在可能会问，是否有可能通过从左到右的自下而上依赖性解析器实现递增性，并且在一般情况下答案结果为“否”。 这可以通过考虑仅包含三个节点的所有可能的投影依赖图并且检查哪些可以递增地解析来证明。 图4显示了相关结构，其中共有七个结构。 2-5都可以实现结构化增量，首先将两个token进栈，2-3使用Right Reduce, 4-5使用Left Reduce， 之后再都进栈，最后2，4再使用Right Reduce, 3,5 使用Left Reduce。 以(2)为例子，进栈2个token, statck: [a,b]使用Right Reduce, 删除b, 产生 $a \rightarrow b$进栈1个token, stack: [a,c]使用Right Reduce, 删除c, 产生 $a \rightarrow c$PS 一般会有个虚拟根节点[ROOT, a, b] 参后 相反，剩下的三个需要先全部进栈才能执行reduction。然而，1和6-7例子解析器不能构成增量解析的原因是不同的。 6-7中前两个节点在最终依赖图中并不是由一条单边连接的。6中前两个全部依赖第三个token.7中巴啦啦拉你懂的。无论使用何种算法，这都必然存在，并且这就是为什么在这里定义的依赖性解析中不可能实现严格的递增性的原因。需要注意的是，作为6-7的镜像2-3，虽然它们包含三个未通过单边相连的相邻token,但它们仍然可以增量解析。原因在于，前两个token的reduction使得第一个与第三个相邻。因此，有问题的结构定义特征是恰好最左的token不直接相连。 1的情况不同之处在于，这是由严格的自下而上的策略引起的，这需要每个token在与其头部结合时要找到其所有的依赖。对于左依赖来说，这没有问题，如5中可以使用Shift和Left-Reduce来交替处理。但在1中，必须从右到左开始。这派出了严格的增量。然而6-7在当前框架中永远不能处理，而1可以修改策略来达到解析。下一节中说明。 在这一点上，与基于扩展分类语法的增量解析进行比较是有益的，其中（6-7）中的结构通常由某种级联（或产品）处理，这与任何真正的语义都不对应。 组成部分的组合（Steedman，2000; Morrill，2000）。 相反，（1）中的结构通常由函数组合处理，其对应于良好定义的组合语义操作。 因此，可能有人认为（6-7）的处理只是伪增量，即使在其他框架中也是如此。 在我们采用严格的自下而上方法之前，可以注意到本节中描述的算法本质上是Yamada和Matsumoto（2003）与支持向量机结合使用的算法，不同之处在于它们允许解析以多个方式执行 传递，其中一次传递产生的图形作为下一次传递的输入.1它们为多次传递解析的主要动机正是自下而上策略要求每个令牌在组合之前找到所有依赖项的事实 用它的头，这也是阻止增量解析结构的原因，如（1）。 4 Arc-Eager Dependency Parsing为了增加确定性依赖解析的递增性，我们需要结合自下而上和自上而下的处理。 更确切地说，我们需要自上而下处理左依赖者自下而上和右依赖者。 通过这种方式，只要相应的头部和从属关系可用，就会将弧添加到依赖关系图中，即使依赖关系对于其自己的依赖关系是不完整的。 在Abney和Johnson（1991）之后，我们将这种热切的解析称为与前一节中讨论的标准自下而上策略区别开来。 使用与以前相同的解析器配置表示，可以通过图5中给出的转换来定义arc-eager算法，其中wi和wj是任意字标记（Nivre，2003）： Left-Arc transition：$w_j \overset{r}{\rightarrow} w_i$，含义是，将下一个输入token $w_j$指向栈顶元素$w_i$并出栈(pop stack) Right-Arc transition：$w_i \overset{r}{\rightarrow} w_j$，含义是，将栈顶元素$w_i$并出栈(pop stack)指向下一个输入token $w_j$,并将$w_j$入栈 Reduce transition 出栈(pop stack) Shift(SH) 将下一个输入token进栈 可以看出，Left-Arc 和 Right-Arc 类似于 Right-Reduce 和 Right-Reduce。它们确保满足单头(Single head)约束，而只当栈顶token有头时候才能使用Reduce trainsition. Shift与之前一样，列表不为空就可以执行。 比较两个算法，Left-Arc 和 Left-Reduce是对应的，但不同在于，出于对称原因，前者适用于栈顶元素token和下一个输入元素token而不是栈顶的两个元素token。但 Right-Reduce 和 Right-Reduce相比，前者并不减少(Reduce)元素而是简单的将新的右依赖项转移(shift)到栈顶，从而使依赖项可以有自己的右依赖项。但是为了允许多个多个右依赖项，必须还有一种机制来弹出栈中的依赖项。这就是 Reduce transition. 因此，我们可以说，标准自下而上算法中右Reduce transitions所执行的动作是通过Right-Arc结合弧激发(arc-eager)算法中的后续Reduce转换来执行的。由于Right-Arc和Reduce可以由任意数量的转换分隔，因此允许对任意长的右依赖链进行增量解析。对于Arc-eager算法而言，定义增量对于标准自下而上算法来说不那么简单。 简单地考虑堆栈的大小将不再起作用，因为堆栈现在可以包含形成依赖图的连接组件的token序列。另外，由于不再必须转移两个tokens组合到栈，并且因为出栈的任意token都可连接到栈的某个token,我们需要保证图 $(S,As)$ 是一直连接的。$As$表示$A$到$S$的约束，如： $As = {(w_i,w_j) \in A | w_i,w_j \in S }$ 给定增量性的定义后，图4中的2-5可以很好使用arc-eager算法的逐步解析，和标准的自下而上算法一样。 \langle \textbf{nil}, abc, \emptyset \rangle \\ \downarrow \textbf{Shift} \\ \langle a,bc, \emptyset \rangle \\ \downarrow \textbf{Right-Arc} \\ \langle bc,a,\{(a,b)\} \rangle \\ \downarrow \textbf{Right-Arc} \\ \langle cba,\textbf{nil}, \{(a,b), (b,c)\} \rangle我们得出结论，相对于依赖性解析中的递增性，arc-eager算法是最优的，即使它仍然适用于图4中的结构（6-7）不能以递增方式解析。接下来的问题是，在实际的解析过程中，出现这样结构的情况有多频繁。这个问题相当于说，Arc-eager算法对严格的增量处理偏离有多少。答案显然取决于选取的语言和理论框架，我们将在下一节来至少谈一谈这个问题。在此之前，我们希望结果能与之前的上下文(context-free)解析联系起来。 首先可以知道，相比于其它context-free解析的标准应用，自下而上和自上而下的术语在依赖解析的上下文中有一点不同的含义。由于依赖图中没有终止节点，自上而下结构表示头节点是在其依赖被绑定前进行绑定的。然而，依赖图中的自上而下结构并不包含从高层节点prediction底层节点，因为所有的节点是输入字符串给定的。因此，就驱动解析过程的因素而言，这里讨论的所有算法都对应于无上下文解析中的自下而上算法。 有趣的是，如果我们将依赖解析的问题重新定义为使用CNF语法的无上下文解析，那么图4中的有问题的结构（1），（6-7）都对应于右分支结构，并且很好 - 已知自下而上的解析器可能需要无限量的内存来处理右分支结构（Miller和Chomsky，1963; Abney和Johnson，1991）。 此外，如果我们在Abney和Johnson（1991）的框架下分析这里讨论的两种算法，它们对于枚举节点的顺序完全不同，而只是对枚举的顺序有所不同;第一种算法是电弧标准，而第二种算法是弧形标准。 Abney和Johnson（1991）提出的观察之一是，无弧上传解析的弧形策略有时可能需要比弧标准策略更少的空间，尽管它们可能会导致局部模糊性的增加。看起来关于图4中结构（1）的依赖关系解析的arc-eager策略的优点可以沿着相同的行解释，尽管依赖图中缺少非终结节点意味着本地没有相应的增加歧义。虽然详细讨论无上下文解析和依赖解析之间的关系超出了本文的范围，但我们推测这可能是依赖表示在解析中的真正优势。 5 Experimental Evaluation结果可以在表1中找到，我们看到在解析613个句子（平均长度为14.0个单词）中使用的16545个配置中，68.9％在堆栈上有零个或一个连接组件，这是我们要求的 一个严格的增量解析器。 我们还发现，大多数违反增量的行为相当温和，因为超过90％的配置在堆栈上的连接组件不超过三个。 许多违反增量的行为是由无法解析为良好的依赖图的句子引起的，即单个映射依赖树，但解析器的输出是一组内部连接的组件。 为了测试不完全解析对增量统计的影响，我们进行了第二个实验，其中我们将测试数据限制为444个句子（613个中），本文生成了一个格式良好的依赖图。 结果可以在表2中看到。在这种情况下，87.1％的配置实际上满足增量性的约束，并且堆栈中具有不超过三个连接组件的配置的比例高达99.5％。 似乎可以得出结论，尽管在确定性依赖性解析中不可能采用严格的逐字增量，但实际上，Arc-eager算法可以被视为增量解析的近似近似。 6 Conclusion本文分析了确定性依赖解析的增量性实现的可能。我们的第一个结果是否定的，因为我们已经证明在这里考虑的限制性解析框架中无法实现严格的增量。然而，我们证明对于增量依赖解析器，考虑到所有的框架约束，arc-eager解析算法是最优的。此外，我们已经表明，在实际解析中，算法对大多数输入结构执行增量处理。如果我们考虑测试数据中的所有句子，则占比大约为三分之二，但如果我们将注意力限制在格式良好的输出上，则几乎为90％。 由于先前已经证明确定性依赖性解析在解析准确性方面具有竞争力（Yamada和Matsumoto，2003; Nivre等，2004），我们认为这个有前景的方法是适应于具有鲁棒性，高效性及(近乎)增量性的需求的。]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>cs224n</tag>
        <tag>nlp</tag>
        <tag>自然语言处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TODO]]></title>
    <url>%2F2018%2F11%2F06%2FTODO%2F</url>
    <content type="text"><![CDATA[[x] Google收录[x] NexT 6.0 公式解析问题[] - Latex公式说明]]></content>
  </entry>
  <entry>
    <title><![CDATA[Springboot使用说明]]></title>
    <url>%2F2018%2F10%2F25%2FSpringboot%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[1. 新建Spring Boot项目 打开Myeclipse,在左侧项目区域右键，选择1new-&gt; web project。填写项目名称并勾选 Add Maven support，选择next，在最后勾选 Standard Maven JEE project structure，选择完成 将sport项目中的pom.xml内容复制覆盖新建项目的pom.xml，修改第一行的项目名称和版本，以及spring-boot-maven-plugin/Application信息。 将Application.java,application.properties文件复制到相应位置。 进行项目包分层。bean,dao,service,contol等 编写测试方法。12345678@RestControllerpublic class Default&#123; @RequestMapping(value="/") public String defaultMethod()&#123; return "&#123;'name':'Jack', 'gender':'female'&#125;"; &#125;&#125; 2. Mybatis generator使用 将mabatis-generator.xml复制到对应位置，并修改其内容，填写JDBC驱动包、待生成路径、数据库对应表等信息。 修改pom.xml，取消mybatis-generator的注释。 右键项目，选择 Run As - Maven build, 在Goals填写mabatis-generator:generate,选择执行。 Maven自动下载包并执行。 3. Spring Boot Jar包生成选择Run As-Maven install会自动生成可运行Jar包。]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2018%2F10%2F25%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[git diffgit diff 比较工作区和暂存区的文件git diff —cached 比较暂存区和版本库的文件git diff —staged 比较暂存区和版本库的文件git diff HEAD 比较工作区和版本库的文件patch 恢复操作 git clonegit clone 克隆项目git colne -b 远程分支 拉取特定分支 git branchgit branch new_branch 创建新的分支git branch -l 显示本地分支git branch -v 显示分支最后commit信息git branch -a 显示远程分支git branch -d branch 删除分支git branch -D 强制删除未合并的分支 git statusgit status -s 简要显示状态信息 git addgit add . 提交所有到暂存区git add -u 将被追踪的文件全部提交到暂存区git add -A 将改动和新加文件提交到暂存区git add -f 强制提交git add -i 交互提交 git checkoutgit checkout 汇总显示工作区、暂存区 与HEAD的差异[显示与origin/master一致与否]git checkout [] 切换分支git checout 目标是工作区的文件git checkout [-q] [] [—] … 使用版本覆盖工作区 如果省略则指定暂存区进行覆盖git checkout 撤销git .add 命令[使用暂存区文件覆盖工作区修改]git checkout branch 将branch所指向的提交中的filename替换暂存区和工作区中相应的文件。git checkout . 重置工作区，使用暂存区进行覆盖git checkout HEAD . 重置工作区，使用版本库进行覆盖git checkout -b / 拉取远程分支并创建新分支 git reset 有：重置指定路径文件 无：重置引用git reset [HEAD] 重置暂存区git reset HEAD —hard 使用版本库重置暂存区和工作区git reset HEAD —soft 仅重置引用，不重置暂存区和工作区git reset [-mixed] HEAD^ 回退一次引用，并使用其覆盖暂存区 git commitgit commit -a 不推荐使用 将追踪文件直接提交git commit —amend 修补命令git commit -c 修改重用提交信息 -C直接使用不修改git commit -F 从文件读取 git stashgit stash list 显示所有git stash save message 保存git stash pop pop Stashgit stash apply 恢复不删除git stash drop 删除git stash clear 清空Stash git taggit tag 显示所有标签git tag -a tagtName -m tagMessage 创建taggit show tagNmae 显示tag详细信息git tag -s GPG密钥签署git tag -v GPG验证git push origin tagName 推送标签到远程版本库git push : 删除远程版本库tag 里程碑共享，必须显式的推送。即在推送命令的参数中，标明要推送哪个里程碑。 执行获取或拉回操作，自动从远程版本库获取新里程碑，并在本地版本库中创建。 如果本地已有同名的里程碑，默认不会从上游同步里程碑，即使两者里程碑的指向是不同的。 git pushgit push 创建远程分支git push : 删除远程分支git remote -v 显示remote信息git remote set-url remoteName 修改remote信息git remote add 添加remote git pullgit pull —rebase 设置变基而不是合并git config branch..rebase true 设置pull默认采用rebase git loggit log —graph 图显日志git log —pretty=online 查看文件提交历史 一种格式化日志输出1git config alias.lg log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset' --abbrev-commit --date=relative core.quotepath=false Tipsgit rm —cache 取消文件追踪git reflog show master | head -5 显示HEAD^ HEAD~3 master@{n} 引用表示git config —global —list 显示git global 配置信息 Markdown 的使用# 一级标题 ##二级标题两个空格换行.+-序列使用*斜体* _斜体_**粗体**，__粗体__]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05-序列模型]]></title>
    <url>%2F2018%2F10%2F25%2F05-%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[05.序列模型 (Sequence Models)第一周 循环序列模型 (Recurrent Neural networks)1.1 为什么选择序列模型？ (Why Sequence Models)循环神经网络在语音识别、自然语言处理等领域有很大应用。 语音识别 音乐生成 情感分类 DNA序列 机器翻译 视频行为识别 命名实体识别 1.2 数学符号 (Notation)给出下面语句： Harry Potter and Herminoe Granger invented a new spell. $x^{}$ 来索引序列中的元素 $y^{}$ 来表示输出数据中的序列元素 $T{x}$来表示输入序列的长度，使用 $T{y}$来表示输出序列的长度 在以前，用$x^{(i)}$来表示第$i$个训练样本，训练样本i的序列中第$t$个元素用$x^{\left(i \right) }$这个符号来表示，$T_{x}^{(i)}$就代表第$i$个训练样本的输入序列长度。 在NLP中，建立Vocabulary，一般规模的商业应用来说30000到50000单词大小的词典比较常见。每个单词可以使用one-hot表示。 还有一点是 如果遇到不在词表中的单词时候，使用一个新的标记Unknow word，用来作为标记 1.3 循环神经网络模型 (Recurrent Neural Network Model)使用标准的神经网络结构来构建学习序列$x$到序列$y$的映射，会遇到下面问题： 不同的样本的输入和输出长度是不相同的 并没有共享从文本的不同位置上学到的特征(如CNN在图像小块学习到的内容可以应用到整个图像) 循环神经网络模型如图：首先构造激活值$a^{}$，这通常是零向量。$x^{}$经过神经网络得到预测值$\hat{y}^{}$。而当第二个单词$x^{}$输入时候，来自时间步(Time-step)1的信息也会输入。这样一直到最后一个时间步，输入$x^{}$，然后输出${\hat{y}}^{&lt; T{y} &gt;}$。至少在这个例子中$T{x} =T{y}$，同时如果$T{x}$和$T_{y}$不相同，这个结构会需要作出一些改变。可以发现，RNN是使用了当前输入的以前信息来综合预测。 He said, “Teddy Roosevelt was a great President.”He said, “Teddy bears are on sale!” 这个例子中，仅仅使用前置单词信息，Teddy并不能被很好的识别为是否为人名，因此出现了BRNN，即双向RNN公式化：$a^{} = g{1}(Wa^{&lt; 0 >} + Wx^{&lt; 1 >} + b{a})$$\hat y^{&lt; 1 >} = g{2}(Wa^{&lt; 1 >} + b{y})$经过整理后：$a^{} =g(W{a}\left\lbrack a^{&lt; t-1 >},x^{t} \right\rbrack +b{a})$$\hat y^{} = g(W{ya}a^{} +b_{y})$ 1.4 通过时间的反向传播 (Backpropagation through time)讲的不够清楚，仅提示是前向传播的反过程。损失函数：$L^{}( \hat y^{},y^{}) = - y^{}\log\hat y^{}-( 1-\hat y^{})log(1-\hat y^{})$将每一个时间步的的损失函数加起来，得到整体损失函数。$L(\hat y,y) = \ \sum{t = 1}^{T{x}}{L^{&lt; t >}(\hat y^{&lt; t >},y^{&lt; t >})}$ 详细需要细看反向传播实现 1.5 不同类型的循环神经网络 (Different types of RNNs) $T{x}=T{y}$不适用的情况是存在的。many-to-one的例子如电影情感分类one-to-many的例子如音乐生成many-to-many的例子如机器翻译，输入与输出的序列是不等长的。 1.6 语言模型和序列生成 (Language model and sequence generation)在自然语言处理中，构建语言模型是最基础的也是最重要的工作之一，并且能用RNN很好地实现。语言模型所做的就是，它会告诉你某个特定的句子它出现的概率是多少。语言模型做的最基本工作就是输入一个句子，准确地说是一个文本序列，$y^{}​$，$y^{}​$一直到$y^{}​$。对于语言模型来说，用$y​$来表示这些序列比用$x​$来表示要更好，然后语言模型会估计某个句子序列中各个单词出现的可能性。如何建立一个语言模型呢？首先需要语料库corpus，然后将语句进行标记化，如使用one-hot形式。一般句尾会增加一个额外标记EOS，表示句尾。再添加一个UNK标记表示不在字典中的字。 $x^{}$设为0向量，这一步其实就是通过一个softmax层来预测字典中的任意单词会是第一个词的概率，$y^{} = x^{}$（上图编号2所示）损失函数： $L\left( \hat y^{},y^{}&gt;\right) = - \sum{i}^{}{y{i}^{}\log\hat y{i}^{}}$ 可记为 $L = \sum{t}^{}{L^{&lt; t >}\left( \hat y^{},y^{} \right)}$ 1.7 对新序列采样 (Sampling novel sequences)论文：（Chung J, Gulcehre C, Cho K H, et al. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling[J]. Eprint Arxiv, 2014. Cho K, Merrienboer B V, Bahdanau D, et al. On the Properties of Neural Machine Translation: Encoder-Decoder Approaches[J]. Computer Science, 2014.） 在你训练一个序列模型之后，要想了解到这个模型学到了什么，一种非正式的方法就是进行一次新序列采样，来看看到底应该怎么做。 首先输入$x^{} =0$，$a^{} =0$，然后第一个时间步会通过softmax概率采样，得到第一个单词$\hat y^{}$，然后将其输入到第二个时间步。一直采样得到EOS标识。有时候采样到UNK，可以忽略或重采样。 实际中可能用到基于字符的RNN结构。优点是不会遇到UNK标识。但缺点序列太多太长，计算成本高。 1.8 循环神经网络的梯度消失 (Vanishing gradients with RNNs) “The cat, which already ate ……, was full.”“The cats, which ate ……, were full.” 这些句子中，cat/cats和was/were有长期依赖性质，但中间的词可以无限长。神经网络可能会遇到梯度消失，所以RNN很难学习这种依赖。梯度爆炸虽然也会出现在RNN中，但梯度消失更难处理。以后课程会详细讲解。 1.9 GRU单元 (Gated Recurrent Unit(GRU))$a^{&lt; t >} = g(W{a}\left\lbrack a^{&lt; t - 1 >},x^{&lt; t >}\right\rbrack +b{a})$，通过上图可以发现，首先将上一个时间步的$a^{}$输入，然后再输入$x^{}$，并在一起后经过激活函数tanh计算得到$a^{}$，然后$a^{}$经过softmax单元可以产生输出$y^{}$。这是最简单的RNN单元。其规则图像如下： The cat, which already ate…, was full. 许多GRU的想法都来分别自于Yu Young Chang, Kagawa，Gaza Hera, Chang Hung Chu和 Jose Banjo的两篇论文。 首先，GRU添加了新的变量$c$(cell)，代表记忆细胞(图中编号1)。GRU实际上输出了激活值$a^{}​$，$c^{} = a^{}​$（图中编号2所示）。仍使用$c^{} $是因为LSTMs会是两个不同值，GRU是一样的。然后经过计算可以得到候选值${\tilde{c}}^{}$，使用tanh函数计算。重点来了，GRU中的门，用$\Gamma{u}$表示：其计算公式为：$\Gamma{u}= \sigma(W{u}\left\lbrack c^{},x^{} \right\rbrack +b{u})$$\Gamma{u}$的值在大多数情况家非常接近0或1。$\Gamma{u}$的作用就是决定什么时候你会更新这个值。更新公式为：$c^{} = \Gamma{u}*{\tilde{c}}^{} +\left( 1- \Gamma{u} \right)*c^{}$ (* 为元素相乘)当$\Gamma_{u}$=1时候，就会更新，为0时候会保持原来的值。 以例句为例子，当到单词cat时候，门值更新，后面一直不需要更新，到了was单词的时候更新。这时候GRU记住了cat是单数。同样的，$\Gamma_{u}$在多个步骤下都=0，即经过几层后，$c^{}$几乎就等于$c^{}$，这就是GRU缓解梯度消失问题的关键。 细节：$c^{}$是一个向量，比如100维，那么$c^{}$也是100维。${\tilde{c}}^{}$也是相同的维度。$\Gamma_{u}$也就100维的向量，里面的值几乎都是0或者1，就是说这100维的记忆细胞$c^{}$（$c^{}=a^{}$上图编号1所示）就是你要更新的比特。 当然在实际应用中$\Gamma_{u}$不会真的等于0或者1，有时候它是0到1的一个中间值（上图编号5所示），但是这对于直观思考是很方便的，就把它当成确切的0，完全确切的0或者就是确切的1。元素对应的乘积做的就是告诉GRU单元哪个记忆细胞的向量维度在每个时间步要做更新，所以你可以选择保存一些比特不变，而去更新其他的比特。比如说你可能需要一个比特来记忆猫是单数还是复数，其他比特来理解你正在谈论食物，因为你在谈论吃饭或者食物，然后你稍后可能就会谈论“The cat was full.”，你可以每个时间点只改变一些比特。 完整的GRU：完整的添加了一个新的门$\Gamma{r}$，$r$代表相关性（relevance）。$\Gamma{r}$门告诉你计算出的下一个$c^{}$的候选值${\tilde{c}}^{}$跟$c^{}$有多大的相关性。计算这个门$\Gamma{r}$需要参数，正如你看到的这个，一个新的参数矩阵$W{r}$，$\Gamma{r}= \sigma(W{r}\left\lbrack c^{},x^{} \right\rbrack + b{r})$。$\Gamma{r}$是研究生试验后选择的，非常健硕和实用。 GRU，即门控循环单元，这是RNN的其中之一。这个结构可以更好捕捉非常长范围的依赖，让RNN更加有效。然后我简单提一下其他常用的神经网络，比较经典的是这个叫做LSTM，即长短时记忆网络，我们在下节视频中讲解。 1.10 长短期记忆(LSTM (long short term memory) unit)论文：Hochreiter S, Schmidhuber J. Long Short-Term Memory[J]. Neural Computation, 1997, 9(8):1735-1780. (比较难) GRU中，$a^{} = x^{}$，并且有两个门： 更新门$\Gamma_{u}$（the update gate） 相关门$\Gamma_{r}$（the relevance gate） LSTM中，有三个门：更新(u)、遗忘(f)、输出(o)LSTM中不再有$a^{} = c^{}$的情况更新与遗忘不再是二选一操作 由红色10号线可以看出，只要设置了正确的遗忘门和更新门，LSTM是相当容易把$c^{}$的值（上图编号11所示）一直往下传递到右边，比如$c^{} = c^{}$（上图编号12所示）。这就是为什么LSTM和GRU非常擅长于长时间记忆某个值，对于存在记忆细胞中的某个值，即使经过很长很长的时间步。 “偷窥孔连接”其实意思就是门值不仅取决于$a^{}$和$x^{}$，也取决于上一个记忆细胞的值（$c^{}$），然后“偷窥孔连接”就可以结合这三个门（$\Gamma{u}$、$\Gamma{f}$、$\Gamma_{o}$）来计算了。如果你读过论文，见人讨论“偷窥孔连接”，那就是在说$c^{}$也能影响门值。 LSTM反向传播计算：门求偏导：$d \Gammao^{\langle t \rangle} = da{next}\tanh(c_{next}) * \Gamma_o^{\langle t \rangle}(1-\Gamma_o^{\langle t \rangle})\tag{1}$ $d\tilde c^{\langle t \rangle} = dc{next}*\Gamma_i^{\langle t \rangle}+ \Gamma_o^{\langle t \rangle} (1-\tanh(c{next})^2)*it*da{next}*\tilde c^{\langle t \rangle}*(1-\tanh(\tilde c)^2) \tag{2}​$ $d\Gammau^{\langle t \rangle} = dc{next}\tilde c^{\langle t \rangle} + \Gammao^{\langle t \rangle} (1-\tanh(c{next})^2) * \tilde c^{\langle t \rangle} * da_{next}\Gamma_u^{\langle t \rangle}*(1-\Gamma_u^{\langle t \rangle})\tag{3}$ d\Gamma_f^{\langle t \rangle} = dc_{next}\tilde c_{prev} + \Gamma_o^{\langle t \rangle} (1-\tanh(c_{next})^2) \* c_{prev} \* da_{next}\Gamma_f^{\langle t \rangle}\*(1-\Gamma_f^{\langle t \rangle})\tag{4}参数求偏导 ： $ dWf = d\Gamma_f^{\langle t \rangle} * \begin{pmatrix} a{prev} \ xt\end{pmatrix}^T \tag{5} $ $ dW_u = d\Gamma_u^{\langle t \rangle} * \begin{pmatrix} a{prev} \ xt\end{pmatrix}^T \tag{6} $ $ dW_c = d\tilde c^{\langle t \rangle} * \begin{pmatrix} a{prev} \ xt\end{pmatrix}^T \tag{7} $ $ dW_o = d\Gamma_o^{\langle t \rangle} * \begin{pmatrix} a{prev} \ x_t\end{pmatrix}^T \tag{8}$ 为了计算$db_f, db_u, db_c, db_o$ 需要各自对$d\Gamma_f^{\langle t \rangle}, d\Gamma_u^{\langle t \rangle}, d\tilde c^{\langle t \rangle}, d\Gamma_o^{\langle t \rangle}$ 求和。 最后，计算隐藏状态、记忆状态和输入的偏导数： $ da_{prev} = W_f^T*d\Gamma_f^{\langle t \rangle} + W_u^T * d\Gamma_u^{\langle t \rangle}+ W_c^T * d\tilde c^{\langle t \rangle} + W_o^T * d\Gamma_o^{\langle t \rangle} \tag{9}​$ $ dc{prev} = dc{next}\Gammaf^{\langle t \rangle} + \Gamma_o^{\langle t \rangle} * (1- \tanh(c{next})^2)*\Gammaf^{\langle t \rangle}da{next} \tag{10}$ $ dx^{\langle t \rangle} = W_f^Td\Gamma_f^{\langle t \rangle} + W_u^T * d\Gamma_u^{\langle t \rangle}+ W_c^T * d\tilde c_t + W_o^T * d\Gamma_o^{\langle t \rangle}\tag{11} $ LSTM和GRU的选择没有准则，GRU模型更加简单，容易创建更大网络，只有两个门，计算也快。LSTM更强大和灵活，拥有三个门。 1.11 双向循环神经网络 (Bidirectional RNN)在这个示例中，仅使用单向RNN不能很好的识别Teddy是否为人名。以四个单词为例子，使用${\overrightarrow{a}}^{}$，${\overrightarrow{a}}^{}$，${\overrightarrow{a}}^{}$还有${\overrightarrow{a}}^{}$，表示前向循环单元，然后添加了${\overleftarrow{a}}^{}$，左箭头代表反向连接，${\overleftarrow{a}}^{}$反向连接，${\overleftarrow{a}}^{}$反向连接，${\overleftarrow{a}}^{}$反向连接，这里的左箭头代表反向连接。最后，这各网络构成了无环图。举个例子，以时间步3来说，$x^{}$经过前向的${\overrightarrow{a}}^{}$到前向的${\overrightarrow{a}}^{}$到前向的${\overrightarrow{a}}^{}$再到$\hat y^{}$。同理$x^{}$可以到达。而对于$x^{}$，可以经过反向的${\overleftarrow{a}}^{}$，到反向的${\overleftarrow{a}}^{}$再到$\hat y^{}$。所以时间3，不仅使用了过去的信息，还有现在的信息。 这就是双向循环神经网络，并且这些基本单元不仅仅是标准RNN单元，也可以是GRU单元或者LSTM单元。事实上，很多的NLP问题，对于大量有自然语言处理问题的文本，有LSTM单元的双向RNN模型是用的最多的。所以如果有NLP问题，并且文本句子都是完整的，首先需要标定这些句子，一个有LSTM单元的双向RNN模型，有前向和反向过程是一个不错的首选。 如果你总是可以获取整个句子，这个标准的双向RNN算法实际上很高效。 1.12 深层循环神经网络 (Deep RNNs)Deep RNN有两种类型：网状、串状 网状：以$a^{\lbrack 2\rbrack }$，上图编号5所示为例子，激活值$a^{\lbrack 2\rbrack }$有两个输入，一个是从下面过来的输入（上图编号6所示），还有一个是从左边过来的输入（上图编号7所示），$a^{\lbrack 2\rbrack &lt; 3 >} = g(W{a}^{\left\lbrack 2 \right\rbrack}\left\lbrack a^{\left\lbrack 2 \right\rbrack &lt; 2 &gt;},a^{\left\lbrack 1 \right\rbrack &lt; 3 >} \right\rbrack + b{a}^{\left\lbrack 2 \right\rbrack})$，这就是这个激活值的计算方法。参数$W{a}^{\left\lbrack 2 \right\rbrack}$和$b{a}^{\left\lbrack 2 \right\rbrack}$在这一层的计算里都一样，相对应地第一层也有自己的参数$W{a}^{\left\lbrack 1 \right\rbrack}$和$b{a}^{\left\lbrack 1 \right\rbrack}$。 串状：没有横向的连接，只有纵向的连接。可以使用简单的RNN单元，也可以使用GRU，LSTM，甚至双向RNN。 第二周 自然语言处理与词嵌入 (Natural Language Processing and Word Embeddings)2.1 词汇表征 (Word Representation)使用one-hot形式表示词汇，每个单词都是独立没有联系的(任何两个单词的内积为零)。因此可以使用词嵌入。这种高维表示，词向量间可以通过计算内积来表示相似度。为了可视化，可以使用t-SNE算法将词向量高维空间映射到二维空间来观察。 2.2 使用词嵌入 (Using Word Embeddings)如何将词嵌入表示应用到NLP中？这是如何用词嵌入做迁移学习的步骤。 第一步，先从大量的文本集中学习词嵌入。一个非常大的文本集，或者可以下载网上预训练好的词嵌入模型，网上你可以找到不少，词嵌入模型并且都有许可。 第二步，你可以用这些词嵌入模型把它迁移到你的新的只有少量标注训练集的任务中，比如说用这个300维的词嵌入来表示你的单词。这样做的一个好处就是你可以用更低维度的特征向量代替原来的10000维的one-hot向量，现在你可以用一个300维更加紧凑的向量。尽管one-hot向量很快计算，而学到的用于词嵌入的300维的向量会更加紧凑。 第三步，当你在你新的任务上训练模型时，在你的命名实体识别任务上，只有少量的标记数据集上，你可以自己选择要不要继续微调，用新的数据调整词嵌入。实际中，只有这个第二步中有很大的数据集你才会这样做，如果你标记的数据集不是很大，通常我不会在微调词嵌入上费力气。 词嵌入技术广泛应用于NLP中的命名实体识别，文本摘要，指代消除等，在语言模型和机器翻译领域使用的少一些。 人脸识别中的术语编码（encoding）和嵌入（embedding）可以互换，差别不是因为术语不一样，这个差别就是，人脸识别中的算法未来可能涉及到海量的人脸照片，而自然语言处理有一个固定的词汇表，而像一些没有出现过的单词我们就记为未知单词。 2.3 词嵌入的特性 (Properties of Word Embeddings)论文：Mikolov T, Yih W T, Zweig G. Linguistic regularities in continuous space word representations[J]. In HLT-NAACL, 2013. 词嵌入能够实现类比推理，准确率在30%~75%左右。对于Man-Woman这种关系，King对应的是那个单词？这时候我们使用Man的词嵌入向量$e{man}$减去Woman的词嵌入向量$e{woman}$，在第一位度表示Gender项可以得到大概-2值，其余项为0。同样，对于King来说，Queen与King的差值向量与之相似。 在向量$u$和$v$之间定义相似度:$\text{sim}\left( u,v \right) = \frac{u^{T}v}{\left| \left| u \right| \right|{2}\left| \left| v \right| \right|{2}}$距离用平方距离或者欧氏距离来表示:$\left| \left| u - v \right|\right|^{2}$测量两个词的两个嵌入向量之间的相似程度。 给定两个向量$u$和$v$，余弦相似度定义如下： ${CosineSimilarity(u, v)} = \frac {u . v} {||u||_2 ||v||_2} = cos(\theta) \tag{1}$ 其中 $u.v$ 是两个向量的点积（或内积），$||u||_2$是向量$u$的范数（或长度），并且 $\theta$ 是向量$u$和$v$之间的角度。角度越小，两个向量越相似。 2.4 嵌入矩阵 (Embedding Matrix)应用算法来学习词嵌入时，实际上是学习一个嵌入矩阵。 例如，假如词汇表长度为1000，词嵌入维度为300。则所有词汇组成的矩阵为3001000。假如6527个单词代表orange，使用符号$O{6527}$来表示这个one-hot向量，这个向量除了6527位置为1，其余全为0。假设嵌入矩阵为$E$，它的第6527列为$e{6527}$表示单词orange的嵌入向量。这时候把矩阵$E$和*one-hot向量相乘，则可以得到$e_{6527}$。在实际中，通常使用一个专门的函数来单独查找矩阵$E$的某列，而不是使用通常的矩阵乘法来做。 2.5 学习词嵌入 (Learning Word Embeddings)假如构建一个语言模型，并且使用神经网络来实现。如预测“I wang a glass of range —”,然后预测下一个词。对于每一个单词使用嵌入向量，然后输入到神经网络中，则可以很好实现词嵌入。如每个单词是300维度，使用前四个单词则是1200的维度输入到神经网络，再经过softmax预测下一个单词。同时你还可以使用6个单词，所以是6x300的维度。这个固定的窗口是算法的超参数。这中算法能很好的学习词嵌入。 其它方式的更加简单的方法是使用不用类型的上下文，使用 目标词的前后各两个词作为上下文，如果目标不是学习语言模型本身的话，可以选择其它上下文也可以使用上下文一个单词，这就是一种Skip-Gram模型的思想，也能得到很好的效果。 2.6 Word2Vec论文：Mikolov T, Chen K, Corrado G, et al. Efficient Estimation of Word Representations in Vector Space[J]. Computer Science, 2013. 在Skip-gram模型中，上下文不一定总是目标最近的$n$个单词，而是随机选择。比如在上下文词前后5个词内或10个词内选择目标词。构建监督学习问题，给定上下文词，预测正负10个词距内随机选择的目标词。我们的目标不是解决监督学习问题本身，而是想要使用它来学习一个好的词嵌入模型。对于一个单词，先构建one-hont向量，然后使用嵌入矩阵得到词向量，$e{c}=EO{c}$。然后将向量$e{c}$喂入一个softmax。$Softmax:p\left( t \middle| c \right) = \frac{e^{\theta{t}^{T}e{c}}}{\sum{j = 1}^{10,000}e^{\theta{j}^{T}e{c}}}$$\theta{t}$是一个与输出$t$有关的参数，即某个词$t$和标签相符的概率是多少。损失函数：$L\left( \hat y,y \right) = - \sum{i = 1}^{10,000}{y{i}\log \hat y{i}}$ 对于词汇过大，softmax计算过慢有两种解决办法，1.分层softmax分类器2.负采样。 模型中对于上下文单词的采样并不是随机抽取，否则 the、of、a、and等词出现相当频繁，而是采用不同的分级平衡。论文中提到了两种模型：Skip-Gram和CBOW，Skip-Gram使用更多些。 2.7 负采样 (Negative Sampling)论文： Mikolov T, Sutskever I, Chen K, et al. Distributed Representations of Words and Phrases and their Compositionality[J]. 2013, 26:3111-3119. 不使用分层softmax，而是使用负采样方式。即构建新的监督学习，给定一堆单词，比如orange和juice，预测是否为一对上下文词-目标词(context-target)。在上个例子中，orange和juice就是一个正样本。再选择k个负样本，即使抽取的词再目标词的范围内也无所谓。k的取值：数据集越大k越小，选择5-20比较好。 当输入词orange，即词6527，得到嵌入向量$e_{6527}$，就得到了10000个可能的逻辑回归分类任务。但我们不在使用上面提到的10000类分类器，而是选择训练其中的$k+1$个，这样计算成本更低。 还有一个细节是负样本的采样过程，既不选择随机抽取，也不通过词频才采样。而是选择下面方式：$P\left( w{i} \right) = \frac{f\left( w{i} \right)^{\frac{3}{4}}}{\sum{j = 1}^{10,000}{f\left( w{j} \right)^{\frac{3}{4}}}}$ 2.8 GloVe 词向量 (GloVe Word Vectors)NLP领域的Glove算法，使用不多，但研究的人页不少。GloVe代表用词表示的全局变量（global vectors for word representation），如果使用$X{\{ij\}}$来表示单词$i$在单词$j$的上下文出现的次数，那么这里的$i$和$j$功能是和$t$ $c$是一样的。如果将上下文定义为左右范围的话，很明显会得到对称关系，但如果规定是单侧方向，就不对称了。不过对于GloVe算法，我们可以定义上下文和目标词为任意两个位置相近的单词，假设是左右各10词的距离，那么$X{\{ij\}}$就是一个能够获取单词$i$和单词$j$出现位置相近时或是彼此接近的频率的计数器。 GloVe模型做的就是进行优化，我们将他们之间的差距进行最小化处理：$\text{mini}\text{mize}\sum{i = 1}^{10,000}{\sum{j = 1}^{10,000}{f\left( X{\{ij\}} \right)\left( \theta{i}^{T}e{j} + b{i} + b{j}^{‘} - logX{\{ij\}} \right)^{2}}}$ 最后，一件有关这个算法有趣的事是$\theta$和$e$现在是完全对称的，所以那里的$\theta{i}$和$e{j}$就是对称的。如果你只看数学式的话，他们（$\theta{i}$和$e{j}$）的功能其实很相近，你可以将它们颠倒或者将它们进行排序，实际上他们都输出了最佳结果。因此一种训练算法的方法是一致地初始化$\theta$和$e$，然后使用梯度下降来最小化输出，当每个词都处理完之后取平均值，所以，给定一个词$w$，你就会有$e{w}^{(final)}= \frac{e{w} +\theta_{w}}{2}$。因为$\theta$和$e$在这个特定的公式里是对称的，而不像之前视频里我们了解的模型，$\theta$和$e$功能不一样，因此也不能像那样取平均。 最后，词嵌入维度的可解释性很差 2.9 情感分类 (Sentiment Classification)情感分类是NLP的重要模块之一，最大的挑战可能是标记的训练集可能没有那么多。比如对一个餐馆的评价，输入$x$是一段文本，输出$y$是要预测的相应情感，分为五颗星。对于情感分类任务，训练集从10,000到100,000个单词都很常见，甚至有时会小于10,000个单词，采用了词嵌入能够带来更好的效果，尤其是只有很小的训练集时。 算法一：将语句用one-hot表示，并转换成词向量，然后将语句的词向量进行求和或求平均，最后将这些特征输入到一个softmax分类器，谭厚输出$\hat{y}$。根据输出结果来进行星级的确定。但是这个算法有个一缺点：”Completely lacking in good taste, good service, and good ambiance.”，但是good这个词出现了很多次，有3个good，如果你用的算法跟这个一样，忽略词序，仅仅把所有单词的词嵌入加起来或者平均下来，你最后的特征向量会有很多good的表示，你的分类器很可能认为这是一个好的评论，尽管事实上这是一个差评，只有一星的评价。 算法二：我们首先取这条评论，”Completely lacking in good taste, good service, and good ambiance.”。找到每一个one-hot，向量，乘以词嵌入矩阵$E$，得到嵌入表达$e$，然后输入到RNN。RNN能够考虑词序问题。这样的算法，会得到一个很合适的情感分类算法。如果词嵌入是一个在更大数据集训练的，这样效果会更好。 2.10 词嵌入除偏 (Debiasing Word Embeddings)论文：Man is to computer programmer as woman is to homemaker?Debiasing word embeddings(Bolukbasi et.al, 2016)这里的bias指的是学习到的知识上的偏见，比如性别歧视，种族歧视等。比如下面这种情况：Man : Woman as King : QueenMan : Computer_programmer as Woman : Homemaker Wrong!Father : Doctor as Mother : Nurse Wrong! 以性别歧视为例子，首先看如何辨别与这个偏见相似的趋势： 对于性别歧视，首先得到$e{\text{he}}-e{\text{she}}$，然后将$e{\text{male}}-e{\text{female}}$，然后将这些值取平均（上图编号2所示），将这些差简单地求平均。这个趋势（上图编号3所示）看起来就是性别趋势或说是偏见趋势，然后这个趋势（上图编号4所示）与我们想要尝试处理的特定偏见并不相关，因此这就是个无偏见趋势。然后偏见趋势看成1D子空间，无偏见趋势就会使299D子空间。当然可以使用更复杂的算法SUV(奇异值分解)来描述偏见趋势的维度大于1. 中和步骤。像grandmother、grandfather、girl、boy、she、he，他们的定义中本就含有性别的内容，不过也有一些词像doctor和babysitter我们想使之在性别方面是中立的。像doctor和babysitter这种单词我们就可以将它们在这个轴（上图编号1所示）上进行处理，来减少或是消除他们的性别歧视趋势的成分，也就是说减少他们在这个水平方向上的距离（上图编号2方框内所示的投影），所以这就是第二个中和步。 均衡步。我们想要确保的是像grandmother和grandfather这样的词都能够有一致的相似度，或者说是相等的距离，和babysitter或是doctor这样性别中立的词一样。 参考资料：针对性别特定词汇的均衡算法 第三周 序列模型和注意力机制3.1 基础模型 (Basic Models)在这一周，你将会学习seq2seq（sequence to sequence）模型，从机器翻译到语音识别，它们都能起到很大的作用，从最基本的模型开始。之后你还会学习集束搜索（Beam search）和注意力模型（Attention Model），一直到最后的音频模型，比如语音。 如何训练一个网络来输入序列$x$和输出序列$y$呢？首先建立一个编码网络(encoder network)，是可以是GRU或LSTM组成的RNN网络。每次只向网络输入一个法语单词，序列接收完成后，得到一个表示序列X的向量。然后建立解码网络(decoder network)，用来输出翻译后的英文单词，一直输出到序列结尾或句子结尾标记。类似语言模型合成文本。 同样的可以应用到图片描述问题，将一张图片输入到AlexNet网络，去掉最后的softmax层，接一个RNN网络输出文本序列。 这两种模型都非常有效，细节之后的课程继续讲。 3.2 选择最可能的句子(Picking the most likely sentence)seq2seq机器翻译模型和之前的语言模型有很多相似之处，但也有重要的区别。 可以把机器翻译模型想象成建立一个条件语言模型。语言模型是估计一个句子的可能性，可以理解$x^{}$是一个全为0的向量，然后$x^{}$、$x^{}$等都等于之前所生成的输出，这就是所说的语言模型。 机器翻译模型中，用绿色标识encoder，紫色标识decoder。与语言模型不同在于，encoder网络会计算一系列向量，并输入到decoder中。decoder并不是以零向量开始，所以把它叫做条件语言模型(conditional language model)。换句话说，你将估计一个英文翻译的概率，所以它是一个语言模型。 现在，假如通过模型来讲法语翻译成英文,通过模型会得到各中英文翻译的可能性。显然，你不想得到随机的输出，所以需要一个算法来找到合适的输出$y$，使得条件概率最大。常用的算法便是束搜索(Beam Search)。 这里需要主义的是和贪心算法作比较，当使用贪心算法的时候，是每次选择概率最大的单词，以下面翻译句子为例：Jane is visiting Africa in September.Jane is gong to be visiting Africa in September.英语中 going更常见， 但第二个句子并没有第一个句子翻译的好。所以$p(y|x)$模型并不是最好的选择。应该以句子为整体来考虑。 另外一点，假设你的字典有10000个单词，翻译的句子假如有10个单词长度。那么组合10,000的10次方这么多，数量非常大。所以近似的算法是尽力去挑选出句子$y$使得条件概率最大化，不一定成功，但已经足够了。 最后总结一下，在本视频中，你看到了机器翻译是如何用来解决条件语言模型问题的，这个模型和之前的语言模型一个主要的区别就是，相比之前的模型随机地生成句子，在该模型中你要找到最有可能的英语句子，最可能的英语翻译，但是可能的句子组合数量过于巨大，无法一一列举，所以我们需要一种合适的搜索算法，让我们在下节课中学习集束搜索。 3.3 集束搜索 (Beam Search)语音识别，机器翻译等，我们想要的都是最好的而不是随机选择一个结果。集束搜索就是为了解决这个问题。 “Jane visite l’Afrique en Septembre.”（法语句子），我们希望翻译成英语，”Jane is visiting Africa in September”.（英语句子）。假如词汇表有10000个单词，然后利用编码网络(绿色)和解码网络(蓝色)来评估di第一个单词的概率。即给定$x$，第一个输出$y$的概率是多少$P(y^{}|x)$贪婪算法只选取最可能的一个，而集束算法有一个参数B，叫做集束宽(beam width)。以3为例，选取最大概率的三个单词并记录概率，假如是in, jane, september。 第二步:针对每一个单词，继续求解词汇中每个单词出现在第二个位置的概率。以in为例，绿色编码，蓝色解码。同时$y^{}$设为单词in，来计算$y^{}$。我们在第二步更关心的出找到最可能的第一个单词和第二个单词对，而不是仅仅第二个单词最大的概率。编号8表示第一个单词的概率，乘以第二个单词的概率(编号9，可以从网络编号10中得到)，最后就得到了第一个和第二个单词对的概率(编号7)。接下来对第二个单词jane继续求解与字典中各单词组成单词对的概率。同样对第三个三次september进行相同的操作。针对第二个单词有10000中不同的选择，集束宽度为3，所以最终会有30000个可能的结果，然后对这30000个结果进行评估，选取前三个结果。这时候可能选取的是in september、jane is、jane visits，这时候可以看到，第一个单词的选择只有两种可能，去掉了september 。接下的步骤与第二步一样，重复这个过程最终得到Jane visits africa in september这个句子，终止在句尾符号(编号8)。集束算法每次只考虑3个可能的结果，当集束宽为1时候就成了贪婪算法了。集束算法会比贪婪算法搜索更好的输出结果。 3.4 改进集束搜索(Refinements to Beam Search)前面讲到束搜索就是最大化这个概率，这个乘积就是$P(y^{&lt; 1 &gt;}\ldots y^{&lt; T{y}}|X)$，可以表示成:$P(y^{}|X)$ $P(y^{&lt; 2 &gt;}|X,y^{&lt; 1 &gt;})$ $P(y^{&lt; 3 &gt;}|X,y^{&lt; 1 &gt;},y^{&lt; 2&gt;})$…$P(y^{&lt; T{y} &gt;}|X,y^{},y^{}\ldots y^{&lt; T_{y} - 1 &gt;})$这些概率都小于1，很多乘在一起就可能造成数值下溢(numerical underflow)，因此，我们在实践中会取$log$值，这样数值会更加稳定，所以在实际工作中，我们记录的是概率的对数和，而不是概率的乘积。 还有一点就是，哪怕采取$log$操作，每一项都是小于1的，因此模型会对短句有偏好，因为越长相乘目标函数的值越小。因此要选择长度归一化：$\alpha$是一个超参数，为0时候完全没有归一化，为1的时候完全归一化，在实践中通常选取0.7，虽然没有理论支持，但效果还不错，你自己以后的项目可以来调节这一参数。有时候也叫这个目标函数为归一化的对数似然目标函数（a normalized log likelihood objective）。 其次，超参数集束宽B也需要调节，同样，B越大，计算成本越大，而且收益由大到小。对于不同的应用和特定的领域来说，10-3000都是可能的。 3.5 集束搜索的误差分析 (Error analysis in beam search)集束搜索是一种近似搜索算法(an approximate algorithm )，也叫启发式搜索(a heuristic search algorithm)。将误差分析和集束搜索结合起来。法语：Jane visite l’Afrique en septembre人工翻译：Jane visits Africa in September 记为$(y^*)$算法翻译：Jane visited Africa last September 记为$(\hat{y})$这个例子中，算法翻译很差，偏离了含义。你的模型有两个主要部分，一个是神经网络或序列到序列模型(seq2seq)，它实际是编码器和解码器。另一个是技术算法，以某个集束宽B运行。如何判断是那个部分出错呢？RNN是计算$P(y|x)$。我们来计算$P(y^*|x)$和$P(\hat y|x)$，然后比较这两个哪个更大，所以就会有两种情况。 $P(y^|x)$ 大于$P(\hat y|x)$。这说明集束算法并没有搜索到正确的结果，所以是集束算法出错了。 $P(y^|x)$ 大于$P(\hat y|x)$。是RNN出错了，这里没有涉及长度归一化(length normalization)，如果使用需要比较的是归一化的最优目标函数。 所以误差分析过程是，首先遍历开发集，然后找出错误并标记各个错误是属于RNN还是集束搜索问题。最后根据分析结果对模型算法进行改进。 3.6 Bleu得分(选修)论文(看)：Bleu:A method for automatic evaluation of machine translation. Papineni et.al., 2002 机器翻译(machine translation)的一个难题是一个法语句子可以有多种英文翻译，并且同样好。这样改如何评价一个机器翻译系统？常用的解决办法就是BLEU得分。BLEU代表bilingual evaluation understudy (双语评估替补)。它背后的理念是观察机器生成的翻译，然后看生成的词是否出现再至少一个人工翻译参考中。 例子：法语：Le hcat est sur le tapis.参考(Reference)1: The cat is on the mat.参考(Reference)2: There is a cat on the mat.机器翻译(MT): the the the the the the the. 这时候，精度(Precision)为$\frac{7}{7}$，因为MT的输出共有7个单词(分母)，其中7个单词出现在两个参考(Reference)中。而修改后的精度(Modified precision)为$\frac{2}{7}$，对于单词the,在两个参考(Reference)中出现的次数分别为2，1。而MT中出现次数为7，超过了最大参考中出现，因此进行截断。所以改良后的精确度评估（the modified precision measure）得分为$\frac{2}{7}$。 目前为止，我们关注的都是单独的单词。我们定义以下二元词组(bigrams)，是指相近的两个单词。同样，可能会考虑一元词组(unigram)，三元词组(trigrams)等。我们首先列出所有的二元词组，然后统计次数，以及截断统计次数可以得到下图：所以二元词组的改良精度为$\frac{4}{6} = \frac{2}{3}$. 现在我们将他们公式化： P_1 = \frac{\sum_{unigram\in y} count_{clip}(unigram)}{\sum_{unigram\in \hat y} count(unigram)}P_n = \frac{\sum_{ngram\in y} count_{clip}(ngram)}{\sum_{ngram\in \hat y} count(ngram)}如果翻译完全一致的话，那么$P_1$、$P_n$的值为1。 细节：我们来组合以下构成最终的BLUE得分。$Pn$就是$n$元词组这一项的BLEU得分，也是计算出的$n$元词组改良后的精确度。首先计算得到$P_1$，$P_2$， $P_3$，$P_4$。然后求和取平均。BLEU定义为$exp (\frac{1}{4}\sum\limits{n=1}^{4}{P_n})$，它是严格单调递增的。我们还会使用一个额外的BP(brevity penalty)惩罚项，用于调整输出偏向短句翻译。 拥有单一实数评估指标(a single real number evaluation metric)是非常重要的。BLEU对机器翻译来说具有革命性的意义。它的开源算法有很多。BLEU得分是一个有用的单一实数评估指标，用于评估生成文本的算法，判断输出的结果是否与人工写出的参考文本的含义相似。不过它并没有用于语音识别（speech recognition）。因为在语音识别当中，通常只有一个答案。 3.7 注意力模型直观理解 (Attention Model Intuition)论文：Bahdanau D, Cho K, Bengio Y. Neural Machine Translation by Jointly Learning to Align and Translate[J]. Computer Science,2014.本节主要讲述Attention model的直观理解，细节在下节。注意力思想已经成为深度学习中最重要的思想之一。 假如翻译的句子非常长，绿色编码器的任务是读取整个句子，然后记忆。紫色神经网络(解码器)将生成英文。而人工翻译是看一点，翻译一点。这个编码器中，它对短语句非常好，BLUE得分会很高，但当句子长度达到30，40时候，表现会非常差。神经网络记忆非常长的句子也是很困难的。所以采用注意力模型，每次只翻译一部分。不会出现长句子得分严重下滑情况。以”Jane visite l’Afrique en septembre”为例子，使用双向RNN可以得到$\hat y^{},\hat y^{},\hat y^{}$等。现在我们构建一个新的注意力机制的单向RNN，首先去掉所有的$Y$输出。然后为了区分感知器(activations)$a^{}$，我们使用$S^{}$来标识RNN的隐藏状态。来看生成第一个单词，我们需要看句子的那一部分呢？应该先看第一个或它附近的单词，因此，用$a{}$来标识生成第一个单词时，原句中第一个单词的注意力权重。$a^{}$它告诉我们当你尝试去计算第一个词Jane时，我们应该花多少注意力在输入的第二个词上面。同理这里是$a^{}$，接下去也同理。然后RNN向前进一次生成一个词，知道最终生成EOS。注意力权重，即$a^{}$告诉你，当你尝试生成第$t$个英文词，它应该花多少注意力在第$t$个法语词上面。当生成一个特定的英文词时，这允许它在每个时间步去看周围词距内的法语词要花多少注意力。 个人理解：双向RNN用来对法语单词进行特征标识，新的RNN中，$S$与$A$效果一致，但输入处的$X$不再是一个单词，而是上下文$C$，$C$是注意力权重与双向RNN的输出(不同时间步的特征值)结合的。细节见下一节 3.8 注意力模型 (Attention Model)上节提到注意力模型如何让一个神经网络只注意到一部分的输入句子。当它在生成句子的时候，更像人类翻译。 首先有一个双向RNN来进行计算每个词的特征。每个单元既可以是GRU，也可以是LSTM，LSTM可能会更常见。一共有五个时间步，前向激活值和后向激活值都有六个。我们使用$t^\prime$来索引法语单词。用$a^{}$来标识时间步上的特征向量。然后设置注意力权重$a{&lt;1,t’&gt;}$。注意力权值和为1。之后计算上下位$C$，其中$C^{} = \sum_{t’}\alpha^{&lt;1,t’&gt;} a^{t’}$。每一个时间步的输入为上下文$C$与上个时间步的输出。 接下来的问题就是该如何定义注意力权重了。用一个小的神经网络来输出各项权重，softmax可以保证权重和为1。相信反向传播，相信梯度下降。 这个算法有一个缺点是它需要花费三次方时间，即$O(n^3)$。如果你有$T_x$个输入单词和$T_y$个输出单词，于是注意力参数的总数就会是$T_x\times T_y$，所以这个算法有着三次方的消耗。但是在机器翻译的应用上，输入和输出的句子一般不会太长，可能三次方的消耗是可以接受，但也有很多研究工作，尝试去减少这样的消耗。 3.9 语音识别 (Speech recognition)将seq2seq应用到语音识别，了解就好。 Attention Model for recognition CTC cost for speech recognition 3.10 触发字检测 (Trigger word detection)可以将触发后的多个label 0改为1，缓解不平衡。 3.11 Thank you! Andrew Ng参考深度学习笔记-黄海广]]></content>
      <categories>
        <category>深度学习[吴恩达]</category>
      </categories>
      <tags>
        <tag>Andrew Ng</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04-卷积神经网络]]></title>
    <url>%2F2018%2F10%2F25%2F04-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[04.卷积神经网络00? 动态性策略如何与DL结合(预测之上的决策系统)？第一周 卷积神经网络1.1 计算机视觉 (Computer vision)将CV知识应用到新的领域，催生新的网络结构目标检测 风格迁移一个64x64的图像，会有12288个维度，一个1000x1000的图像，会有3M个维度，假如第一层神经元有1000个，则$w^{[1]}$有3B个参数，这太大了！故需要卷积 1.2 边缘检测示例 (Edge detection example)*是卷积操作的标准符号对卷积不了解可详细看这个视频参考论文 1.3 更多边缘检测内容 (More edge detection)固定的卷积核：Sober过滤器： - - - 1 0 -1 2 0 -2 1 0 -1 Scharr过滤器： - - - 10 0 -3 10 0 -10 3 0 -3 另一种思想：将9个数字作为参数进行学习，是CV的有效思想之一。 1.4 Padding普通的卷积操作 输出减少，$output: (n-k)+1$，输出图片变小 丢失了图像边缘的大部分信息 对原始图片进行填充，如用0填充，则输出(n+2p-k)+1=6，图像保持不变。Valid convolution:不使用填充，$n\times n * f\times f \rightarrow (n-f+1) \times (n-f+1)$Same convolution:使用填充，保持图片大小不变。$n+2p-f+1 \times n+2p-f+1$ 继续求解可得$p = \frac{f-1}{2}$卷积核一般为奇数 1.5 卷积步长 (Strided convolution)输出图片维度(向下取整)：$\lfloor \frac{n+2p-f}{s}+1 \rfloor$按机器学习惯例，不使用翻转操作，技术上讲，可能叫互相关更好，深度学习中叫做卷积操作。 1.6 三维卷积 (Convolutions over volumes) 输出：$n\times n \times n_c * f\times f \times n_c \rightarrow n-f+1 \times n-f+1 \times n_c’$ $n_c$是channel， $n_c’$是卷积核的数量 1.7 单卷积层网络 (One layer of convolution network) 假如有10个3x3x3的卷积核，则该层的参数为280个。而无论你的输入的图片大小是多少，参数个数是不变的，即使用10个特征提取。卷积之后得到feature_map，与偏置项$b$相加，得到$z^{[l]}$，然后再应用激活函数得到$a^{[l]}$ $f^{[l]}$是卷积核的大小，$n_c^{[l]}$是卷积核的个数$p^{[l]}$是padding, $s^{[l]}$是步长输入为上一层的输出，所以为$n_H^{[l-1]} \times n_w^{[l-1]} \times n_c^{[l-1]}$卷积计算：$n_H^{[l]} = \frac{n_H^{[l-1]}+2p^{[l]}-f^{l}}{s^{[l]}} + 1$，同理$n_w^{[l]}的计算$每一个卷积核(过滤器)维度：$f^{[l]} \times f^{[l]} \times n_c^{[l-1]} $，$n_c^{[l-1]}$是上一层输出的channel。激活函数：$a^{[l]} = n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}$权重Weights：$f^{[l]} \times f^{[l]} \times n_c^{[l-1]} \times n_c^{[l]}$，$n_c^{[l]}$是卷积核的个数偏置项bias：$n_c^{[l]}\rightarrow(1,1,1,n_c^{[l]})$ 1.8 简单卷积网络示例 (A simple convolution network example)假设输入图片大小：$n{H}^{[0]} = n{W}^{[0]}=39$，$n_{c}^{[0]} =3$第一层卷积：10个$f^{[1]} = 3$，$s^{[1]} = 1$，$p^{[1]} =0$，则$a^{[1]}=$37×37×10第二层卷积：20个$f^{\left\lbrack 2 \right\rbrack}=5$，$s^{\left\lbrack 2 \right\rbrack}=2$，$p^{\left\lbrack 2 \right\rbrack} = 0$，则$a^{\left\lbrack 2 \right\rbrack}=$17x17x20第三层卷积：40个$f^{\left\lbrack 3 \right\rbrack}=5$，$s^{\left\lbrack 3 \right\rbrack}=2$，$p^{\left\lbrack 3 \right\rbrack} = 0$，则$a^{\left\lbrack 3 \right\rbrack}=$7x7x40=1960最后处理成向量，接softmax或logistic回归函数 典型的卷积神经网络层： Convolution (Conv) Pooling (POOL) Fully connected (FC) 1.9 池化层 (Pooling layers)Max pooling:如果在卷积核中提取到某个特征，则保留其最大值，如果没有提取到，最大值也很小。仅是直观理解，但实验效果良好。步长和大小不需要学习。p一般为0Average pooling:不太常用。 1.10 卷积神经网络示例（Convolutional neural network example）类似于Le-Net-5逐步讲解各卷积层的输出维度有的文献将卷积和池化作为一层神经网络。随着网络的加深，高度$n{H}$和宽度$n{W}$通常都会减少，而通道数量会增加。 在神经网络中，另一种常见模式就是一个或多个卷积后面跟随一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个softmax。这是神经网络的另一种常见模式。 有几点要注意，第一，池化层和最大池化层没有参数；第二卷积层的参数相对较少，前面课上我们提到过，其实许多参数都存在于神经网络的全连接层。观察可发现，随着神经网络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能。示例中，激活值尺寸在第一层为6000，然后减少到1600，慢慢减少到84，最后输出softmax结果。我们发现，许多卷积网络都具有这些属性，模式上也相似。 1.11 为什么使用卷积神经网络 (Why convolutions?)卷积神经网络的优点： 参数共享：特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域，共享特征选择器。 稀疏连接：如32x32x3 = 3072 使用6个5核卷积得到28x28x6=4704，如果用传统的全连接则需要3072x4704=14M参数，而卷积只需要(5x5+1)x6=156个参数。同时，映射后的feature_map某一像素点只和整张图片中的25个像素点有关联，所以是稀疏连接。 Parameter sharing: A feature detector (such as a vertical edge detector) that’s useful on one part of the image is probably useful in another part of the image.Sparsity of connections: In each layer, each output value depends only on a small number of inputs. 卷积网络可以使用任何的代价函数$J$，以及其它梯度下降算法(Momentum,RMSprop,Adam) 第一周作业卷积神经网络的反向传播 第二周 深度卷积网络：实例探究 (Deep convolutional models: case studies)2.1 为什么要进行实例探究 (Why look at case studies?)通过他人案例学习建立卷积神经网络的直觉与技巧。尝试读计算机视觉(CV)论文提纲： 经典网络 LeNet-5 1980 AlexNet VGG ResNet 训练了深达152层的网络 Inception 2.2 经典网络 (Classic networks) LeNet-5 离线阅读论文发表于1998年，当时使用的平均池化，也没有采用padding。LeNet-5在全连接最后一层使用的不是softmax，而是另一种，现在很少用到的分类器。此外，当时使用的激活函数为Sigmoid和tanh，而不是ReLu。PPT内容大部分来自于论文II和III，精读第II段，泛读第III段。 AlexNet 离线阅读AlexNet使用227x227x3(原文使用224x224x3)图片作为输入，部分卷积层使用了padding，还是用了复杂的GPU计算，激活函数选取的ReLu，最后一层使用softmax，同时使用了局部响应归一化层”（Local Response Normalization），即LRN层,LRN效果没多大作用。 VGG-16VGG-16 虽然包含16个看似很多的的网络层，但结构并不复杂。首先卷积核(过滤器)的数量，64-128-256-512-512。 如果你对这些论文感兴趣，我建议从介绍AlexNet的论文开始，然后就是VGG的论文，最后是LeNet的论文。虽然有些晦涩难懂，但对于了解这些网络结构很有帮助。 2.3 残差网络 (Residual Networks (ResNets))ResNet论文中将逐层传播网络定义为plain network，而ResNet的不同就是添加了”short cut/skip connection”，形成了Residual block。示意图：在第二层线性变化后，非线性激活前，添加一样$a^{[l]}$，即$a^{[l+1]} = g(z^{[l+1]} + a^{[l]})$ 整个网络示意图：残差网络解决了梯度消失或爆炸，允许网络结构更加深层。 残差网络为什么有效 (Why ResNet work)设想一个神经网络的输出为$a^{\left\lbrack l \right\rbrack}$， 我们在它后面添加带“residual block”的两层网络。此时，$a^{\left\lbrack l + 2\right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$。如果使用L2正则化，那么权重$W^{[l+1]}$会被压缩，$b$偶尔也会被压缩，注意$W$，如果$W^{\left\lbrack l + 2 \right\rbrack} = 0$，为方便起见，假设$b^{\left\lbrack l + 2 \right\rbrack} = 0$，这几项就没有了，因为它们（$W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2\right\rbrack}$）的值为0。最后$ a^{\left\lbrack l + 2 \right\rbrack} = \ g\left( a^{[l]} \right) = a^{\left\lbrack l\right\rbrack}$，因为我们假定使用ReLU激活函数，并且所有激活值都是非负的，$g\left(a^{[l]} \right)$是应用于非负数的ReLU函数，所以$a^{[l+2]} =a^{[l]}$。 事实上，残差块学习这个恒等式函数并不难。从上面可以看出，即使网络添加了两层，但它的效率比没有降低，所以将残差块放到网络中间还是末尾，都不影响网络。 此外，如果这些隐层能学到一些拥有东西，比恒等式表现还好，那网络可以提升效果，或者说至少不会降低。 一个细节：ResNets使用了需要SAME卷积，保证了$a^{\left\lbrack l\right\rbrack}$与残差块的维度一致，当不一致的时候，在残差块中添加一个科学系参数$W_s$，即$a^{\left\lbrack l + 2\right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack} + W_s \cdot a^{\left\lbrack l\right\rbrack})$ 论文中，使用卷积-卷积-卷积-池化 -卷积-卷积-卷积-池化….最后使用softmax 2.5 网络中的网络以及1x1卷积 (Network in Network and 1x1 convolutions)对于通道为1的6x6图片，使用1x1卷积核似乎作用并不大，仅仅是对二维数组进行了扩大或缩放。 但对于通道为32的6x6输入来说就不一样了，这时候我们使用一个1x1的卷积核(实际维度为1x1x32，卷积核通道与输入通道一致)。这时候的卷积操作，是将输入中的一个1x1x32的切片，乘以1x1的卷积核中32个不同的权重再求和，最后应用ReLU激活函数。当然这是1个卷积核，如果是32个卷积核，则效果如下： 这种方法通常称为1×1卷积，有时也被称为Network in Network，在林敏、陈强和杨学成的论文中有详细描述。虽然论文中关于架构的详细内容并没有得到广泛应用，但是1×1卷积或Network in Network这种理念却很有影响力，很多神经网络架构都受到它的影响，包括下节课要讲的Inception网络。 这时候输入输出的通道数量保持一致，因此改变卷积核的数量可以进行通道的压缩与扩充(池化仅仅压缩图片的高和宽) 2.6 Google Inception network 简介Inception层或Inception网络可以用来代替人工来确定卷积层中的过滤器类型(1x1?3x2?5x5?)。 从图中可以发现会设计大量的计算，我们先来看一下5x5的卷积计算成本。对于28x28x192的输入，采用32个5x5(x192)的卷积进行操作，计算量为 28x28x32 x 5x5x192 = 120M(120422400) 32个核 每个核参数为 5x5x192 做一次卷积需要的stride为 28x28 所以计算成本为 32x5x5x192x28x28 而考虑下面的结构： 对于28x28x192的输入，我们想要得到和之前一样的输出维度28x28x32，先使用16个1x1(x192)的核卷积，再使用32个5x5(x16)的核卷积。其计算量为 28x28x16 x 192 = 2.4M 28x28x32 x 5x5x16=10.0M,总计为12.4M，与上面的结果相比，缩小了10倍。 所以$ 1\times1 $卷积核作为“bottleneck layer”的过渡层能够有效减小卷积神经网的计算成本。事实证明，只要合理地设置“bottleneck layer”，既可以显著减小上层的规模，同时又能降低计算成本，从而不会影响网络的性能。 2.7 Inception 网络通过计算成本的对比，可以发现使用1x1的卷积核能够简化计算量，因此可以构建Inception module： 有了Inception module，则Google的gooLeNet网络就很好理解了： 该模型使用多个Inception Module，此外模型多两个softmax输出，能对网络进行调整，并防止过拟合。Inception网络还有很多新版本，如Inception V2、V3以及V4，还有一个版本引入了跳跃连接(skip connection)的方法，有时也会有特别好的效果。 2.8 使用开源的实现方案 (Using open-source implementations)熟练使用GitHub，如REstNets实现 2.9 卷积网络的迁移学习 (Transfer Learning)如果建立自己的CV检测器，可以下载神经网络的开源实现，不仅包括代码，还包括权重。这样，修改最后一层的softmax层，freeze前面的神经网络，然后在你的数据集上进行训练。 一个经验是，你的数据量越大，你需要freeze的层数越小，甚至仅仅把它们来当作初始化参数。CV中，迁移学习是很值得考虑去做的。 2.10 数据增强 (Data argumentation)数据扩充方式： 镜像(Mirroring) 随机裁剪(Random Cropping) 其它实现比较复杂的方式：旋转，扭曲， 色彩转换，使用PCA颜色增强(AlexNet有细节，也有其它开源实现) CPU并行：几个线程或进程做数据增强，其它CPU或GPU训练网络。 2.11 计算机视觉现状 (The state of computer vision)语音识别、图像识别、目标检测任务现所有的数据一个比一个少。数据越少的任务可能越需要手工工程。 在机器学习应用时，学习算法有两种知识来源。 Labeled data Hand engineered features / network architecture / other components 在缺乏数据的情况下，获取良好的表现方式还是花更多时间进行架构设计，或者在网络架构上花费更多时间。 Benchmark 基准测试，Benchmark是一个评价方式，在整个计算机领域有着长期的应用。维基百科上解释：“As computer architecture advanced, it became more difficult to compare the performance of various computer systems simply by looking at their specifications.Therefore, tests were developed that allowed comparison of different architectures.”Benchmark在计算机领域应用最成功的就是性能测试，主要测试负载的执行时间、传输速度、吞吐量、资源占用率等。 在基准/竞赛中提升效果 集成 Ensembling Train several networks independently and average their outputs 多折验证 Muti-crop at test time Run classifier on multiple versions of test images and average results 集成大概可以提高1%或2%，但消耗时间。Muti-crop 是说将你的测试图片进行多次裁剪，每张都进行预测，然后综合考虑结果。这两种方式在实际生产情况下，很少考虑，在基准测试和竞赛上做得很好。 最后，其他人可能已经在几路GPU上花了几个星期的时间来训练一个模型，训练超过一百万张图片，所以通过使用其他人的预先训练得模型，然后在数据集上进行微调，你可以在应用程序上运行得更快。当然如果你有电脑资源并且有意愿，我不会阻止你从头开始训练你自己的网络。事实上，如果你想发明你自己的计算机视觉算法，这可能是你必须要做的。 第三周 目标检测3.1 目标定位识别一张图片中是否有车的分类问题已经很熟悉了，现在还要输出车在图片中的位置，即定位分类问题Classification with Location。进一步，如果图片中包含多个物体需要定位，就是目标检测。 例：识别一张图片是1 行人 2 汽车 3 自行车 4 背景 类别。首先记图像左上角为(0,0)，右下角记(1,1)。图像的边框用bx,by,bh,bw来表示中心坐标点和宽高。这时候神经网络的输出向量可以定义为$[P_c,bx,by,bh,bw,c1,c2,c3]$。$pc$表示是前三类与否，如果为1，则$bx,by,bh,bw$来表示坐标，$c1,c2,c3$来表示具体的某一类。此外，损失函数也需要修改： L(\hat{y},y)=\begin{cases} \sum_i(\hat{y}_i-y_i)^2& \text{if} \ y_1=1\\\\ (\hat{y}_1-y_1)^2& \text{if} \ y_1=0\\ \end{cases}实际中，可以不对$c{1}$、$c{2}$、$c{3}$和softmax激活函数应用对数损失函数，并输出其中一个元素值，通常做法是对边界框坐标应用平方差或类似方法，对$p{c}$应用逻辑回归函数，甚至采用平方预测误差也是可以的。 3.2 特征点检测 (Landmark detection)如果需要检测64个人脸关键点，则可以使卷积神经网络输出为129个，第一个代表有无人脸，剩余的表示各个特征的坐标。 3.3 目标检测 (Object detection)使用卷积神经网络进行对象检测，采用是基于滑动窗口的目标检测算法。选用不同的窗口和步长会有一定的影响，太小计算量大，太大影响效果。不过计算成本得到了解决，见下。 3.4 卷积的滑动窗口实现 (Convolutional implementation of sliding windows)之前讲的滑动检测计算效率太低，其中一个原始是因为重复计算问题。而现在，不需要将图片每次切割单独放入神经网络去计算，可是将卷积神经网络的最后全连接层也改用为卷积层。输入也只需要输入原图片完整一次。 改写全连接层：假如输入图片是14x14x3，经过16的5x5卷积得到10x10x16，再经过池化得到5x5x16。连接两个400个节点的全连接层，输出四分类向量。改写成卷积层：前面一致，得到5x5x16特征后使用400个5x5的窗口可以得到1x1x400向量，再使用400个1x1的窗口，可以得到1x1x400向量，最后使用1x1的窗口可以得到1x1x4的向量。 一次计算假如训练数据为14x14x3，而测试图片数据为16x16x3，按切分的话，可以将16x16x3切分成四部分，然后每部分输入网络进行计算。但这样需要计算四次，且重复计算区域较大。可以将16x16x3图片直接输入网络，得到的2x2x4分别代表切割的四部分结果。 3.5 Bounding Box预测 (Bounding box predictions)参考论文：YOLO You Only Look Once: Unified real-time object detection 论文比较难懂。 上节讲到的滑动窗口卷积实现算法效率很高，但仍有一个问题，不能输出最精准的边界框。 YOLO(you only look once)算法： 假设输出维度为8：{px, bx, by, bh, bw, c1, c2, c3}。将原始100x100的图片划分为3x3的格子，对每个格子使用分配y标签(8维)。然后训练输出各个格子的y。最后整个输出为3x3x8的维度。 当然，你可以切分更细，使用19x19边框，这个单个边框内包含多个目标的可能性更小。 其中一个细节：bx,by,bw,bh都是[0,1]的，以每个边框的左上角为(0,0)坐标，右下角为(1,1)坐标。 3.6 交并集 (Intersection over union)目标检测算法的评估参数：交并集(lou)：$\frac{交集面积}{并集面积}$。一般lou&gt;0.5。这个阈值可以人为设置，很少小于0.5。lou衡量了两个边界框的重叠相对大小。 3.7 非极大值抑制(Non-max suppression)先假设对象检测中只有一种对象，但算法通常会检测出多次。如在19x19=361个格子检测，会得到很多格子检测包含目标，但很多检测的是同一个目标。非极大值抑制是说，对于同一个检测物体的多个检测边界，仅输出最大概率的，抑制其它边界输出。对于多目标类别检测，正确的做法是独立进行多次非极大值抑制。 3.8 Anchor Boxes当两个识别目标居于同一个格子时候，该如何处理呢？之前的目标检测都只能在一个格子里检测一个对象。以一个格子最多两个对象为例子，首先根据目标的特性人为规定两个Anchor Boxes，比如竖着的为人，横着的为车。然后格子的类别标签y不在是8维度，而是16维度。前8维度为Anchor Boxes1的标签，后八个维度为Anchor Boxes2的标签。 如何选择Anchor Boxes呢？可以使用K-Means对对象进行聚类，然后得到形状。 3.9 YOLO 算法将训练集图片分成3x3格子，需要检测三类对象：行人，汽车，摩托车。使用两个anchor box。第一个格子和第八个格子的标签如图。 在预测的时候，一个目标的情况很容易理解。而对于下图： 对于每一个grid call，得到两个预测边界框 去掉概率低的预测 对每个类别(行人，汽车，摩托车)使用非极值抑制算法。最后只得到最后一个预测。3.10 R-CNN首先得到候选区域，再进行CNN卷积识别。 R-CNN 使用图像分割算法，选取候选区域，然后使用滑动窗口方式卷积 Fast R-CNN 类似于第四节，不再单个框输入而是一次全部，但速度还是比较慢。 Faster R-CNN 使用CNN来选择候选区域。 第4周4.1 什么是人脸识别 (What is face recognition?) 人脸验证(Verification) 输入照片和姓名(ID) 输出图像是否为本人 人脸识别(Recognition) 拥有$K$个人脸的数据库 输入图像 输出人物ID如果他是$K$个人中之一 很显然，在人脸验证的任务中，准确率达到99%是可以接收的，但放到识别任务中，100个人则代表1%的失误状况，所以人脸识别需要较高的准确率。 人脸验证之所以困难，原因之一是要解决”一次学习(one-shot learning problem)“问题。 4.2 One-Shot学习 (One-Shot learning)如果识别人有四个人，使用ont-hot来表示输出，这种方式不太好，如果新加入一个人脸，则ont-hot维度需要改变。同时，一半人物只有一张照片，使用一张照片不能有效训练完成一个稳健的神经网络。 为了解决One-Shot问题，可以使用”similarity“ function。使神经网络学习一个$d$表示的函数，$d(img1, img2) = degreed\ of \ difference\ between\ images$。它以两张图片作为输入，然受输出两张图片的差异值。差异值小于某个阈值$\tau$，它是一个超参数，表明是同一个人。 4.3 Siamese网络 (Siamese network)论文：DeepFace closing the gap to human level performance Siamese网络，学习函数$d$来计算两张人脸的相似度。思想是，将人脸编码(映射)成固定维度向量(非one-hot)将$x^{(1)}$和$x^{(2)}$的距离定义为这两幅图片的编码之差的范数，$d( x^{( 1)},x^{( 2)}) =|| f( x^{( 1)}) - f( x^{( 2)})||_{2}^{2}$。如果$x^{(i)}$和$x^{(j)}$是同一个人，则$||f(x^{(i)}) - f(x^{(j)})||^2$很小，相反很大。使用反向传播来学习网络参数。如果定义真正的目标函数呢？使用三元组损失函数 4.4 Triplet损失 (Triplet loss)论文：FaceNet: A Unified Embedding for Face Recognition and Clustering Anchor Positive Negative用三元组术语来说，对于一个Anchor图片，Positive图片和其是同一个人，距离更近，Negative非同一个人，距离更远。简写成$A$,$P$,$N$三元组损失，我们的目标是想要$|| f(A) - f(P) ||^{2}$，你希望这个数值很小，准确地说，你想让它小于等$f(A)$和$f(N)$之间的距离，或者说是它们的范数的平方（即：$|| f(A) - f(P)||^{2} \leq ||f(A) - f(N)||^{2}$）。（$|| f(A) - f(P) ||^{2}$）当然这就是$d(A,P)$，（$|| f(A) - f(N) ||^{2}$）这是$d(A,N)$，你可以把$d$ 看作是距离(distance)函数，这也是为什么我们把它命名为$d$。网络中的参数全为0的话，也是可以满足条件的，为了避免这个问题，添加一个超参数$\alpha$，代表间隔margin。最后我们可以定义损失函数： L(A,P,N) = max(||f(A) - f(P)||^2 - ||f(A) - f(N)||^2 + \alpha, 0)不难发现，当$|| f( A) - f( P)||^{2} -|| f( A) - f( N)||^{2} + \alpha \ge 0$，则得到一个正的损失值。 相反，网络不会关心负值大小。 对于训练集，至少保证一个人有多张图片。训练的时候，可以随机选取照片来构成APN三元组，但使用相近图像的AP才能更好地训练网络。人脸识别模型可以选择其它公司或研究机构训练好的网络模型。 4.5 面部验证与二分类 (Face verification and binary classification)论文：DeepFace:Closing the gap to human-level performance in face verification 除了Triplet loss方法外，还可以把人脸识别看作二分类问题。选取一堆Siamese网络，将两章图片进行编码(映射)，然后输入逻辑回归单元如Sigmoid，进行输出1或0。此时损失函数为： \hat{y} = \sigma ( \sum_{k=1}^{128} \omega_i |f(x^{(i)})_k - f(x^{(j)})_k| + b) $f(x^{(i)})$是图片$x^{(i)}$的编码，$k$代表第$k$个元素。 这样就可以将其转化成二分类问题。 4.6 什么是神经风格转换 (What is neural style transfer)我将使用$C$来表示内容图像，$S$表示风格图像，$G$表示生成的图像。 4.7 什么是深度卷积网络？(What are deep ConvNets learning?)论文：Visualizing and Understanding Convolutional Networks 通过可视化卷积神经网络分析可以发现，层数越高，网络学习到的内容越复杂。 4.8 代价函数 (Cost function)代价函数包含两部分： $J_{\text{content}}(C,G)$，内容代价函数，用来度量生成图片$G$的内容与内容图片$C$的内容有多相似。 $J_{\text{style}}(S,G)$，风格代价函数，用来度量图片$G$的风格和图片$S$的风格的相似度。 最终的代价函数为($\alpha$ 是权重超参数)： J( G) = a J_{\text{content}}( C,G) + \beta J_{\text{style}}(S,G)4.9 内容代价函数 (Content cost function)$J( G) = \alpha J{\text{content}}( C,G) + \beta J{\text{style}}(S,G)$内容代价函数： 选取隐层$l$来计算内容代价， use hidden layer l to compute content cost. 使用预训练的卷积神经网络，如VGG 使用$a^{[l]\lbrack C\rbrack}$和$a^{[l]\lbrack G\rbrack}$来表示两个图片$C$和$G$的$l$层的激活函数值。 如果这两个激活值相似，那么就意味着两个图片的内容相似。 内容代价函数求得就是两个图片之间$l$层激活值差值的平方和。 4.10 风格代价函数 (Style cost function)论文：A neural algorithm of artistic style 风格的数据表达：相关性(correlation)计算$l$层的输出，通道间的相关性。风格矩阵(style matrix)使用$a{i,\ j,\ k}^{[l]}$来表示隐层$l$中$(i,j,k)$位置的激活项，$i$，$j$，$k$分别代表该位置的高度、宽度以及对应的通道数。计算风格矩阵$G^{l}$，它是一个$n{c} \times n_{c}$的矩阵，同样地，我们也对生成的图像进行这个操作。 $G{kk^{‘}}^{[l][S]} = \sum{i = 1}^{n{H}^{[l]}}{\sum{j = 1}^{n{W}^{[l]}}{a{i,\ j,\ k}^{[l][S]}a_{i,\ j,\ k^{‘}}^{[l][S]}}}$ 用符号$i$，$j$表示下界，对$i$，$j$，$k$位置的激活项$a{i,\ j,\ k}^{[l]}$，乘以同样位置的激活项，也就是$i$,$ j$,$k’$位置的激活项，即$a{i,j,k^{‘}}^{[l]}$，将它们两个相乘。然后$i$和$j$分别加到l层的高度和宽度，即$n{H}^{[l]}$和$n{W}^{[l]}$，将这些不同位置的激活项都加起来。$(i,j,k)$和$(i,j,k’)$中$x$坐标和$y$坐标分别对应高度和宽度，将$k$通道和$k’$通道上这些位置的激活项都进行相乘。我一直以来用的这个公式，严格来说，它是一种非标准的互相关函数，因为我们没有减去平均数，而是将它们直接相乘。 同样计算生成图像的的风格矩阵：$G{kk^{‘}}^{[l][G]} = \sum{i = 1}^{n{H}^{[l]}}{\sum{j = 1}^{n{W}^{[l]}}{a{i,\ j,\ k}^{[l][G]}a_{i,\ j,\ k^{‘}}^{[l][G]}}}$ Gram matrix，所以用$G$来表示。 最后，整体的风格代价函数为两个风格矩阵的F范数的平方，可以乘以一个归一化常数，或者乘以一个超参数$\beta$就好了。 $J{style}^{[l]}(S,G) = \frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2} \sum_k \sum{k’}(G{KK’}^{[l][S]} - G{KK’}^{[l][G]})$ 最终，整体的代价函数为：$J(G) = a J{\text{content}( C,G)} + \beta J(S,G)$ 4.11 一维到三维推广 (1D and 3D generalizations of models)卷积操作可以应用到1D和3D上，1D可以使用序列模型，会在下次课程中讲解并对比。应用到3D，channel层是额外的。 参考深度学习笔记-黄海广]]></content>
      <categories>
        <category>深度学习[吴恩达]</category>
      </categories>
      <tags>
        <tag>Andrew Ng</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03-结构化机器学习项目]]></title>
    <url>%2F2018%2F10%2F25%2F03-%E7%BB%93%E6%9E%84%E5%8C%96%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[03.结构化机器学习项目第一周1.1 为什么是ML策略经验：如何进一步优化模型 1.2 正交化正交化是指，在模型的调参过程中，尽量选择影响单一化的方法。 第一组按钮用来调节宽度，方法包括 - bigger network - Adam算法第二组按钮用来调节高度，方法包括 - 正则化 - 增加数据集第三组 - 增加数据集第二组 - 改变损失函数 - 改变开发数据集 一般不使用early stopping,它会同时影响前两步,违反正交化,使模型不好分析。 1.3 单一数字评估指标使用单一数字(实数)指标进行模型的评估。如F1值：$\frac{2}{\frac{1}{P}+\frac{1}{R}}$重申：idea&lt;-&gt;code&lt;-&gt;experiment 1.4 满足和优化指标当有多个指标去衡量目标的话，可以选择一个作为优化指标(optimizing metric)，其它的设置为满足指标(satisficing metric) 如猫学习器准确率作为optimizing metric，识别速度小于100ms作为satisficing metric 如语音唤醒设备，准确率作为optimizing metric，24小时内只能一次假阳性唤醒作为satisficing metric 1.5 训练/开发/测试集的划分开发集/保留交叉验证集 和 测试集 应保持数据同分布新收集的数据也应同时分布在开发集和测试集上 1.6 开发集和测试集的大小传统的8:2或6:2:2方式不再适合大数据下的当代深度学习对训练数据量的要求非常大，因此，当数据大于百万时候，使用98:1:1是没有问题的。一般强调设置 训练集、开发集、测试集有时候忽略测试集不推荐 1.7 什么时间开始改变开发/测试集和指标如果无法正确评估好算法的排名，则需要定义一个新的评估指标。 算法a在识别猫图时可能会推送成人图片，则需要修改error指标： Error: \frac{1}{m_{dev}} \sum_{i=1}^{m_{dev}}L({\hat y}^{(i)},y^{(i)}) \tag{1}Error: \frac{1}{\sum \omega^{(i)}} \sum_{i=1}^{M_{dev}}\omega^{(i)}L({\hat y}^{(i)},y^{(i)}) \tag{2}\omega^{(i)}= \begin{cases} 1& \text{if} \ x^{i}\ \text{is non-porn}\\\\ 10& \text{if} \ x^{i}\ \text{is porn} \end{cases} 在当前开发集和测试集表现很好，但在实际应用中表现不好时，需要修改指标换切换数据集。 1.8 为什么是人的表现贝叶斯最优误差(Bayes optimal error)是理论上可能达到的最优误差，如果你的模型比人类水平低，说明可以使用某些工具来提高性能。模型效果低于人类水平，你可以 人为标注更多类别数据 人工误差分析：为什么人类做的对？ 更好的偏差/方差分析 1.9 可避免偏差将人类水平看作是贝叶斯误差，贝叶斯误差和训练集的错误率记为可避免偏差(Avoidable bias)， 当可避免偏差过大，要先降低训练集的错误率。如情况A 当可避免偏差很小，解决方差。如情况B 1.10 理解人的表现Human-level error定义:替代贝叶斯误差。 一般人对放射科的识别误差为3% 一般医生的误差为1% 专家医生的误差为0.7% 专家团队的误差为0.5% 可以得知 bayes error &lt;= 0.5%比较Avoidable bias 和 Variance大小可以分析应解决偏差还是方差问题。 1.11 超过人的表现 Scenario Human-level training set error development error A 0.5% 0.6% 0.8% B 0.5% 0.3% 0.4% 在情况A下Avoidable Bias为0.1，Variance为0.2，故应该着重降低方差。但在情况B下，模型超过人类，很难用现有的工具和方法去判断应降低偏差还是方差。在结构化数据中，机器学习算法很容易超越人的表现。但在自然感知领域，人类比较擅长，但机器学习能够一定程度上超过人类。 1.12 改善你模型的表现 减小可避免偏差 更大的模型 训练更久，优化算法(momentum, RMS prop, Adam, activation function) 更换网络结构(RNN,CNN)，超参数搜索 减小方差 更多数据 正则化(L2, Dropout, data augmentation) 更换网络结构(RNN,CNN)，超参数搜索 第一周作业选择题 可参考网上相关资料 第二周2.1 进行误差分析误差分析：通过人工检查分析错误样本点，来进行下一步的优化。 一个猫分类器错误地将狗识别成了猫，目前误差是$10\%$是否应该专门去处理狗？误差分析： 随机抽取开发集中100个错误样本 统计狗的数量结果： $5\%$是狗，则花费很多时间处理狗，误差会从$10\%$降低到$9.5\%$，即性能提升的Ceiling为$9.5\%$。 $50\%$是狗，那么误差会从$10\%$降低到$5\%$，值得尝试。 多个想法的并行评估猫分类器的优化idea: 修复狗识别成猫问题 修复狮子等大猫被错误分类 更好地图片模糊处理 Image Dog Great Cats Blurry 分析中新的类别 Comments 1 ✔ 比特犬 2 ✔ 3 ✔ ✔ 动物园下雨 … … … … %of total 8% 43% 61% 12% - 然后通过人为分析，比如解决Great Cats问题，或同时解决图像模糊问题。这个统计步骤大概需要几小时，但是值得。 2.2 清除标注错误的数据深度学习对随机误差(少量的数据标记出错)鲁棒性(robust)，但对系统误差没有。在误差分析的时候添加一列：数据标记类别出错，进行分析。是否进行样本类别修正? 如果这些标记错误严重影响了模型在开发集的评估能力，需要修复。 没有，则不需要花费宝贵时间修正。 第一种情况下，其它错误占9.4%远大于标记错误问题，所以应多处理其它错误。第二种情况下，标记错误类别比较大，需要处理。 修正开发集/测试集错误样本 在开发集，测试集上使用相同的处理，保证数据同分布 同时检查算法中正确和错位的样例 训练集和开发测试集处于轻微的不同分布。之前提到训练集对随机误差有鲁棒性，且训练集比开发测试集大很多，不做标记修正也是可以的，之后细谈这个问题。 深度学习不仅是使用模型，还更多在模型优化，调参，分析误差上。 2.3 快速搭建你的第一个系统，并进行迭代快速建立原型系统，然后进行迭代。 快速设立开发测试集和评估指标 建立机器学习系统原型 使用偏差/方差分析和误差分析决定下一步 如果研究的问题有大量的文献参考资料，可以先了解然后一开始就建立比较复杂的模型 2.4 在不同的划分上进行训练和测试训练集和开发测试集要保持同分布不一定完全对 一、 想要训练识别APP用户上传的猫图分类器，有200K网页抓取猫图(清晰)数据，和10KApp用户上传数据(真实应用，模糊不专业)。这种情况下去做数据的划分有两种选择： 将两个数据集合并打乱，划分如下。虽然保证了数据的同分布，但在开发集2.5K数据中，仅有119张是App数据，靶心更多地指向了网页抓取猫图，因此，这种方式是不可行地。 | 训练集 | 开发集 | 测试集 | | 205k | 2.5k | 2.5k | 将App的10K数据分为2.5k,2,5k,5k。两个2.5k分别作为开发集和测试集，5k和网页抓取200K数据一起作为训练集，虽然训练集和开发测试集数据分布不同，但靶心是正确的。 二、想要建立一个汽车后视镜语音识别模型，有买的语音识别数据500k，和与后视镜交互的真实应用数据20k数据集的划分应该为，将真实数据中的5K分别做开发集和测试集，剩余的进行训练集 2.5 不匹配数据划分的偏差和方差偏差和方差分析可以帮助你进行下一步的优化，训练集和开发测试集的数据分布不同时候，偏差和方差分析方法需要调整。需要设立训练-开发集(train-dev set)进行分析。训练-开发集(train-dev set)：和训练集同分布，但没有用于训练。 误差分析情况示例： - Scenario A Scenario B Scenario C Scenario D Human-error - - 0% - Train error 1% 1% 10% 10% Train-dev error 9% 1.5% 11% 11% Dev error 10% 10% 12% 20% Problem Variance data mismatch Bias Bias &amp; data mismatch avoidable error:Human-error - Train errorvariance:train error - train-dev errordata mismatch: train-dev error - dev errordegree of overfit:dev error - test error 考虑下面的情况： 编号 - - 与上一行差值 1 Human-error 4% - 2 Train error 7% avoidable error 3 Train-dev error 10% variance 4 Dev error 6% data mismatch 5 Test error 6% degree of overfit 2,3是根据训练集分布评估的，4,5是根据开发集分布评估的，需要一个更通用的分析，以汽车后视镜语音为例： - General speech recognition Reaview mirror speech data Human level human level 4% 6% Error on examples on trained Traing error 7% 6% Error on examples on not trained Training-dev error 10% Dev/Test error 6% 首先分析红色四个数据，能给出优化方向把表格中右上两个数字得到，左右对比分析很有用最后一行说明实际任务对比训练任务更简单，但一行差值又表明不是那么简单data mismatch没有很系统的解决方法，但有一些尝试建议 原图如下： 2.6 定位数据不匹配数据不匹配问题进行误差分析，1）尝试了解两个数据分布的不同之处，2）收集等多的像开发集一样的数据，如通过人工合成数据。使用人工合成数据要警惕：从所有可能性的空间只选取了很好一部分去模拟数据，从而导致算法对这一部门过拟合。 以汽车后视镜语音系统为例子可以在清晰的数据集上人为与汽车噪声数据合成，但注意，汽车噪声不应该仅仅是一个小时，而应该是很大的，近似于清晰数据集。不然很容易对这一小时的汽车噪声过拟合。 2.7 迁移学习迁移学习的应用场景： 当你想从任务A并迁移一些知识到任务B，当任务A和任务B都有同样的输入X时，迁移学习时有意义的。 当你拥有任务A的数据大于任务B时候 任务A的低层特征对任务B是有效的 迁移学习将神经网络最后一层或多层进行重新初始化和训练，迁移学习又叫预训练。 2.8 多任务学习多任务学习使用频率低于迁移学习多任务学习比单任务学习效果要好，如果不好说明网络不够深多任务学习在计算机视觉，目标检测有很广应用。多任务学习最后一层不再使用softamx，单一样本的类别不再是onehot向量表示，$y$成为各个类别的0，1表示。损失函数：$Loss=\underset{(4,1)}{\hat{y}^{(i)}}$变为：$\frac{1}{m}\sum_i^m\sum_j^4L(\hat{y}_j^{(i)}, y_j^{(i)})$ 2.9 什么是端对端的深度学习以前的数据处理系统或学习系统，需要多个阶段的处理，end to end learning则是忽略所有这些不同的阶段，用单个神经网络来代替它。但端对端学习并不使用所有场景： 百度的人脸门禁系统，将其拆分成1.判断是否有人脸并进行图片切割2.判断人物身份 机器翻译，使用端对端学习相比传统的一步步收取特征再转换有效，且有大量的数据集 根据手骨判断儿童年龄，数据量太小。无法支撑端对端学习，而传统的切割手骨判断长度再判断年龄比较合适 2.10 是否使用端对端学习优势： 让数据说话(黑盒)。不要强迫机器学习C A T，以音位为单位去学习进行语音识别。(联想到用语法做文本分析，结果一沓糊涂) 降低手工设计的组件需要 劣势： 需要非常大量的数据 排除了可能有用的手工设计组件，精心设计的组件可能很有用，也可能限制学习器的学习思维。 使用端对端(end to end learning)的建议：关键：是否拥有足够的数据来学习从x到y足够复杂(complexity needed)的函数。无人驾驶技术，并不是简单的端对端学习：而是把DL用来学习构成部分组件。 深度学习做预测，决策是更上层的目标。-沈华伟 参考深度学习笔记-黄海广]]></content>
      <categories>
        <category>深度学习[吴恩达]</category>
      </categories>
      <tags>
        <tag>Andrew Ng</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02-改善深层神经网络]]></title>
    <url>%2F2018%2F10%2F24%2F02-%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[02.改善深层神经网络第一周 深度学习的实用层面1-1 训练/开发/测试集以前一般使用7:3划分训练集测试集或6:2:2 。大数据下通常需要用验证集快速验证多种算法的优劣，所以可以去小一些。百万数据集98：1：1%确保验证集合测试集的数据来自同一分布 1-2 偏差/方差欠拟合：偏差过高 过拟合：方差过高高方差：训练集和验证集的错误率相差过大高偏差：与人类等实际分类效果对比太差如果可以确定最优方差 然后去和偏差方差作比较来评价模型 1-3 机器学习基础High bias? Bigger network Train longer NN architecture search (可选)拟合训练集后，再看 High variance? More data regularization NN architecture search (可选) 1-4 正则化L1 正则化 $\omega$稀疏，但没有压缩模型减少内存L2 正则化又称权重衰减(Weight Decay) 公式可见权重在减小 1-5 为什么正则化可以减少过拟合L2 正则化防止过拟合 直观经验是权重越多接近于0 模型越简单(存疑)以Sigmoid为例 当权重过小时候，Sigmoid是接近线性的，整个网络是线性的从而使模型变为简单来减少过拟合 1-6 Dropout(Inverted dropout)d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_proba3 /= keep_prob以Hinton论文中提出的Dropout在测试集上是将概率$p$应用到神经元的输出边上为了简化测试集的操作，在训练时候每个神经元的输出都降低为权重$1/p$ 这样就不需要在测试集做额外操作 BN与Dropout的冲突解决方式：1. 先使用BN后使用Dropout, 更甚仅在softmax前一层使用 2.使用Uout 1-7 理解DropoutDropout 有效性体现： 等效正则化，使网络更简单 神经元不在完全依赖特定的输入神经元 可以设置不同层$\omega$的dropout rate 设置为1表示不使用dropoutDropout主要同于计算机视觉(CV)，当过拟合的时候可以在使用缺点： 损失函数的定义不对明确 调试困难(先固定为1， J递减再开启) 1-8 其他正则化技术 Data Augmentation 数据增强 如 图片旋转、裁剪、扭曲 early stooping have a mid-size rate $||W||_{2F}$通常的训练步骤： 优化代价函数J(GD/ Momentum/ RMRprop /Adam) 避免过拟合(正则化) | 减少方差(正交化)early stooping 不能独立处理问题1 2 1-9 正则化输入 Normalization training sets0均值 1方差当特征范围不一致时候使用归一化，加速$J$下降 1-10 梯度消失和爆炸1-11 神经网络的权重初始化$z = W_1x_1+W_2x_2+…+W_nx_n$设置$var(Wi) = 1/n W^{[l]} $=np.random.rand(shape)*np.sqrt(1/n[l-1])最后一项tanh 使用Xavier 初始化，ReLU使用公式2 Xavier 初始化，公式： $\sqrt{\frac{1}{n^{[l-1]}}}$公式： $\sqrt{\frac{2}{n^{[l-1]}+n^{[i]}}}$ 此超参数的调节优先等级比较低 1-12 梯度的数值逼近双边误差法：$f(\theta) = \frac{f(\theta+\epsilon) - f(\theta-\epsilon)}{2\epsilon}$ 1-13 梯度检验$J(\theta) -&gt; d\theta$$10^{-7}$ 效果great $10^-3$效果wrong 1-14 梯度检验经验 Dont use in training - only to debug If algorithm fails grad check, look at components to try to identify bug Rember regularization Doesn’t work with dropout Run ai random initialization;perhaps again after some training 第一周第一次作业权重初始化作用： 加速梯度收敛 增加泛化能力 权重初始化对比 0 随机 HE三种方式结果逐渐变好 其中He Initialization (Xavier Initialization变种 参考) 权重为0 $cost$不下降模型无效权重过大，没有效果 第一周第二次作业正则化技术很有效 第一周第三次作业梯度检验： difference = \frac {\| grad - gradapprox \|_2}{\| grad \|_2 + \| gradapprox \|_2 } \tag{3}第二周 优化算法2.1 Mini-batch梯度下降法默认梯度下降是将所有数据进行计算实现一部梯度下降分批次 : $X = {X^{\{1\}}, X^{\{1\}}, …, X^{\{m\}} }$同样：$Y = \{Y^{\{1\}}, Y^{\{1\}}, …, Y^{\{m\}} \}$mini batch $t:X^{\{t\}}, Y^{\{t\}}$ $x^{(i)}$表示训练集中第$i$个训练样本$z^{[l]}$表示神经网络的层数$X^{\{i\}} \ Y^{\{i\}}$表示不同的mini batch $X$维度$(n_x, \text{batch size})$ 1234567891011121314# 遍历批次 每批次使用向量化for t=1,....5000:&#123; # 使用X^&#123;t&#125; Y^&#123;t&#125; 实现 一步 梯度下降 Forward prop on X^&#123;t&#125; Z^[1] = W^[1]X^&#123;t&#125; + b^[1] A^[1] = g[1](Z^[1]) . . . A^[l] = g^[l](Z^[l]) Compute cost J^&#123;t&#125; Back prop update W,B&#125; 2.2 理解mini-batch梯度下降法损失表现mini-batch 的成本函数是震荡下降的 选择mini-batch sizeTips: 将mini-batch size 设置为m : Batch Gradient Descend 将mini-batch size 设置为1 : stochastic gradient descent(随机梯度下降) batch gradient descend的cost轨迹，相对噪声低，幅度大stochastic gradient descent的cost轨迹，噪声大，徘徊在最小值 缺点：失去了向量化的加速处理 一般使用合适batch size的mini-batch 其优点： 向量化 不全部使用数据集 size 选取： 样本集小直接使用batch gradient descent ($m\leqslant 2000$) mini-batch size 一般为 [64，128，256，512] 一般为2的次方 保证$X^{\{t\}}, Y^{\{t\}}$ 与CPU/GPU内存相适应 2.3 指数加权平均指数加权平均(exponentially weighted averages)又称指数加权移动平均(exponentially weight moving averages)以温度为例,$V0 = 0$$V_1 = 0.9 \cdot V_0 + 0.1 \cdot \theta_1$$V_2 = 0.9 \cdot V_1 + 0.1 \cdot \theta_2$$V_3 = 0.9 \cdot V_2 + 0.1 \cdot \theta_3$…$V_t = 0.9 \cdot V{t-1} + 0.1 \cdot \theta_t$效果如图： $Vt = \beta V{t-1} + (1-\beta) \theta_t$当$\beta = 0.9 ：\approx \frac{1}{1-\beta} = 10\ (dayTemperature)$当$\beta = 0.98 ：\approx \frac{1}{1-\beta} = 50\ (dayTemperature)$当$\beta = 0.5 ：\approx \frac{1}{1-\beta} = 2\ (dayTemperature)$对比效果图如下： 红色0.9(10天平均温度) 绿色0.98(50天平均温度) 黄色0.5(2天平均温度)平均天数越大图像越平滑，越偏移平均天数越小噪声越大 选定参数对模型有一定的影响 2.4 理解指数加权平均 $vt = \beta v{t-1}+(1-\beta)\theta_t$ $V{100} = 0.9v{99}+0.1\theta{100}$$V{99} = 0.9v{98}+0.1\theta{99}$$V{98} = 0.9v{97}+0.1\theta{98}$…$V{100}=0.1\cdot\theta{100}+0.1\cdot0.9\theta{99}+0.1\cdot(0.9)^2\theta{98}+0.1\cdot (0.9)^3\theta{97}…$ 0.9^{10} \approx 0.35 \approx \frac{1}{e} \label{1}(1-\epsilon)^{\frac{1}{\epsilon}} \approx \frac{1}{e}即，经过10天后，权重下降到原来的三分之一当$\beta = 0.98$时，需要指数50能达到$\frac{1}{\epsilon}$，即可以看作是平均了50天温度可以使用\frac{1}{1-\beta}来表示平均了多少数据(非正式数学证明) 2.5 指数加权平均的偏差修正(bias correction)当$t_0 = 0$时，$V_1 = \beta V_0+(1-\beta )\theta_1 = (1-\beta )\theta_1$，会发现前期数据值比较小 。 紫线是实际图形，对比绿线发现，前期数值偏小，后期重合 偏差修正$\frac{V_t}{1-\beta^t}$ 用来解决前期偏差过大问题，随着$t$的增加，偏差修正无效。在机器学习中，大家都不在乎使用偏差修正，大部分人喜欢熬过前期。如果关心初期的偏差，就需要使用它。 2.6 动量梯度下降法MomentumMomemtum 在梯度下降中，我们希望朝最优解进向横向速度越大，纵向震荡越小越好。 Momemtum对于优化碗形状损失函数比较适用 Implementation detailsOn iteration t: compute $dW$,$db$, on the current mini-batch $v{dW} = \beta v{dW}+(1-\beta)dW$ $v{db} = \beta v{dWb}+(1-\beta)db$ $W = W -\alpha v{dW}, b=b-\alpha v{db}$Hyperparameters:$\alpha ,\beta$ $\beta = 0.9$(平均十次数据) 不使用偏差修正 $dW$ $db$ 可以理解为加速度$v{dW}, v{db}$ 可以理解为速度前项$\beta &lt; 1$可以理解为摩擦力 Tip: 有一些资料中删除了后项的$(1-\beta)$参数， 即$v{dW} = \beta v{dW}+dW$得到的$v_{dW}$缩小了$(1-\beta)$倍这要求学习率$\alpha$要与$(1-\beta)$相应变化，影响了$\alpha$的最优值此外，如果调整$\beta$ 则需要对应调整$\alpha$ 所以不选择此实现方式 2.7 RMSpropRMSprop(root mean square prop)可以消除梯度下降算法中的摆动，加速梯度下降，可以使用更大学习率我们希望在$\text{w}$更新更快，在$\text{b}$减小震荡从一个蓝色箭头中可以看出$dw$比较大，$db$比较小(即梯度)因此在更新时候加上相关项来处理 $\text{w}$ 和 $\text{b}b$ 表示高维中的参数 不仅代表w,b 实现： 在迭代$t$中计算 mini-batch 中的$dw$,$db$$S{dw} = \beta S{dw} + (1-\beta)(dw)^2$$S{db} = \beta S{db} +(1-\beta)(db)^2$$w = w-\alpha \frac{dw}{\sqrt{S{dw}}}$$b = b- \alpha \frac{db}{\sqrt{S{db}}}$$(dw)^2$ 变小 w更新越大 $(db)^2$ 变大 b更新越大特别的为了防止$\sqrt{S{dw}}$过小，会添加一项$\epsilon$ : $w = w-\alpha \frac{dw}{\sqrt{S{dw}+\epsilon}}$ $b = b- \alpha \frac{db}{\sqrt{S_{db}+\epsilon}}$ $\epsilon$一般取值$10^{-8}$效果示意图为绿线 2.8 Adam 优化算法Adam优化算法是把Momentum和RMSprop算法结合在一起算法流程： $V{dw} = 0, S{dw} = 0, V{db} = 0, S{db} = 0$在迭代$t$：使用mini-batch 计算 $dw$, $db$$V{dw} = \beta_1V{dw}+(1-\beta1)dw, V{db} = \beta1v{db}+(1-\beta1)db $ &lt;- “momentum” $\beta_1$$S{dw} = \beta2S{dw}+(1-\beta2)(dw)^2, S{db} = \beta2S{db}+(1-\beta2)(db)^2 $ &lt;- “RMSprop” $\beta_2$# 要进行偏差修正$V{dw}^{corrected} = V{dw}/(1-\beta_1^t), V{db}^{corrected} = V{db}/(1-\beta_1^t)$$S{dw}^{corrected} = S{dw}/(1-\beta_2^t), S{db}^{corrected} = S{db}/(1-\beta_2^t)$# 更新系数$W=W-\alpha \cdot \frac{V{dw}^{corrected}}{\sqrt{S{dw}^{corrected}+\epsilon}}, b = b-\alpha\cdot\frac{V{db}^{corrected}}{\sqrt{S_{dw}^{corrected}+\epsilon}}$ 超参数的选择$\alpha : 需要调整$$\beta_1:0.9 -&gt;(dw)$$\beta_2:0.999 -&gt;(dw^2)$$\epsilon:10^{-8}$一般使用默认就好，不需要特别修改Adam : Adaption momentum Estimator 2.9 学习率衰减epoch:完整的使用一次全部数据集 $\alpha = \frac{1}{1+decay_rate*epoch_num}$ $\alpha = 0.95^{epoch_num}\cdot \alpha_0$ $\alpha = \frac{k}{\sqrt{epoch_num}}\cdot \alpha_0$ 离散化衰减 手动衰减 2.10 局部最优的问题鞍点(saddle point)问题：在各维度导数为0，但部分维度是凸函数顶点 unlikely to get stuck in a bad local optima(不太可能陷入局部最优的最佳点) Plateaus can make learning slow(平滑区域导致学习变慢，Adam能加速学习逃离) 第二周作业 Momentum 随机梯度下降和批量梯度下降的区别在于，在一次计算梯度时候所使用的训练集样本数量(The difference between gradient descent, mini-batch gradient descent and stochastic gradient descent is the number of examples you use to perform one update step.) 必须调整学习率(You have to tune a learning rate hyperparameter $\alpha$ .) 参数设置很好的批量梯度下降算法，比梯度下降和随机梯度下降算法要高效，特别在数据集大情况下(With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large).) Adam \begin{cases} v_{W^{[l]}} = \beta_1 v_{W^{[l]}} + (1 - \beta_1) \frac{\partial J }{ \partial W^{[l]} } \\\\ v_{W^{[l]}}^{corrected} = \frac{v_{W^{[l]}}}{1 - (\beta_1)^t} \\\\ s_{W^{[l]}} = \beta_2 s_{W^{[l]}} + (1 - \beta_2) (\frac{\partial J }{\partial W^{[l]} })^2 \\\\ s_{W^{[l]}}^{corrected} = \frac{s_{W^{[l]}}}{1 - (\beta_2)^t} \\\\ W^{[l]} = W^{[l]} - \alpha \frac{v_{W^{[l]}}^{corrected}}{\sqrt{s^{corrected}_{W^{[l]}}}+\varepsilon} \end{cases} 适合mini-batch 和 momentum 稍微调整超参数就能很有效($\alpha$除外) 第三周 超参数调试、Batch正则化和程序框架3.1 调试处理系统超参数调试技巧 $\alpha$ 第一级别重要$\beta$(默认0.9) mini-batch size 和 #hidden units 第二级别重要learning rate decay 和 #layers 第三级别重要$\beta_1(0.9),\beta_2(0.999), \epsilon(10^{-8})$基本不用修改 超参数搜索原则：先随机取值再精确搜索 随机取值:不是网格取值 精确搜索:缩小范围 3.2 为超参数选择合适的范围对参数选择良好的尺度(scale)，不是使用区间随机取值，而是将区间通过指数变换成整数值来随机抽取。如学习率$\alpha$范围为[0.0001, 1],直接随机抽取，搜索资源90%会落在[0.1,1]12r = -4 * np.random.rand() #[-4, 0]alpha = 10 ** r #[10^-4, 10^0] 3.3 超参数选取实战：Pandas vs. Caviar Pandas：在CPU/GPU资源较少的情况下，在一个模型上不同时间调整学习率，查看损失函数表现 Caviar：在计算资源充足条件下，并行跑多个模型，选择最好的模型参数 3.4 正则化网络的激活函数 Batch Normalization 吴恩达推荐的是在激活函数之前对$Z$进行归一化，与BN网络论文一致。参考论文：BN_PDFD和BN笔记BN与Dropout的冲突解决方式：1. 先使用BN后使用Dropout, 更甚仅在softmax前一层使用 2.使用Uout \mu = \frac{1}{m}\sum_i z^{(i)} \sigma^2 = \frac{1}{m}\sum_i(z^{(i)}-\mu)^2 z_{norm}^2=\frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\epsilon}} \bar{z}^{(i)} = \gamma z_{norm}^{(i)} + \beta $\gamma$和$\beta$是为了防止归一化限制输入特征的的表现。 当$\gamma = \sqrt{\sigma^2+\epsilon}$，$\beta=\mu$，只是一个恒等函数。 3.5 将Batch Normalization 拟合进神经网络 BN应用在每一个神经元激活函数之前的计算结果$z$，同时BN使参数偏置项$b$无效 [Appendix] 神经网络训练步骤 BN与Dropout的冲突解决方式：1. 先使用BN后使用Dropout, 更甚仅在softmax前一层使用 2.使用Uout1234567891011121314151617181920212223242526272829303132333435363738split x_train,y_train,x_test,y_testset hyper parameters: batch_size learning_rate learning_rate_decay beta1,beta2 keep_probeinit parameters(He Initialization): w, gamma,beta #？存疑for e in epoch: for i in iteration: # 1. forward propagation # 1.1 compute Z (dw)(db deprecated by BN) Z = W * a # 1.2 BN (dgamma,dbeta) Z = BN(Z) # 1.3 activation function a = g(Z) # ... iterate L neural layer # gradient parameters: dw,dgamma,dbeta # 1.4 droupout (applied on last hidden layer) a = a * d a /= keep_prob # 2. back paopagation dw, db, dbeta = computeGradient(Z) # 2.1 momentum vdw = beta1 * vdw + (1-beta1) * dw vdw_corrected = vdw/(1-beta1 ** i) # same as other gradient parameters # 2.2 RMSprop sdw = beta2 * sdw + (1-beta2) * dw ** 2 sdw_corrected = sdw/(1-beta2 ** i) # 2.3 update parameters w = w - learning_rate * ( vdw_corrected / math.sqrt(sdw_corrected + episilon) ) # same as other gradient parameters 3.6 Batch Norm 为什么奏效 归一化使输入均值为0，方差为1，能够加速学习。 固定了各神经层间的输入分布变化，因而使神经元能更好地学习 BN的额外功能：正则化 数据被缩放 添加噪声，使神经元不再特定依赖 轻微的正则化效果 3.7 测试时的 Batch Norm和BN论文说明不太相同。在训练BN网络地时候，训练数据集分为$X ^{\{1\}}$,$X^{\{2\}}$,$X^{\{3\}}$…$X^{\{m\}}$对于第一层地一个神经元可以得到$X^{\{1\}[1]}$,$X^{\{2\}[1]}$,$X^{\{3\}[1]}$……每一层的每一个神经元，都会得到$m$个$\mu$和$\sigma$以第l层第n个神经元为例，将其$m$个$\mu$使用指数加权平均方法进行处理$vi = \beta v{i-1} + (1-\beta)\mu^{\{i\}}$在测试集的时候BN仅仅是一个线性变化，利用指数加权平均计算各层神经元的$\mu$和$\sigma$参数 3.8 Softmax 回归 y(a^{[L]})= \frac{e^{z^{[L]}}}{\sum z^{[L]}}Softmax 用来归一化概率Softmax 激活函数的特殊：输入为向量，输出为向量，其它激活函数输入为单值无隐层的Softmax网络可以用于多分类，学习到的决策边界都是线性的。 3.9 训练一个Softmax分类器softmax是和hardmax相对应的。(hardmax形式[0,1,0,0]) Softmax regression generalizes logistic regression to C classes Softmax是logistic的多分类应用。Loss Function: L(\hat{y},y)=-\sum_{j=1}^C y_j log\hat{y}_j如$C=4$，$y=[0,1,0,0]$，$a^{[L]}=\hat{y}=[0.3,0.2,0.1,0.4]$,则: L(\hat{y},y)=0+y_2 \dot log\hat{y}_2+0+0=-log\hat{y}_2即损失函数定义是正确类别的概率越大(最大似然估计)训练集的代价函数J=(\omega^{[i]},b^{[i]}...)=\frac{1}{m}\sum_{i=1}^m L(\hat{y},y)实现梯度下降：\frac{\partial J}{\partial z^{[L]}} = dz^{[L]} = \hat{y}-y 深度学习框架选择指标： 易于编程 运行速度 真正开源 部分深度学习框架： Caffe/Caffe2 PyTorch Keras Tensorflow Theano mxnet 参考深度学习笔记-黄海广]]></content>
      <categories>
        <category>深度学习[吴恩达]</category>
      </categories>
      <tags>
        <tag>Andrew Ng</tag>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Blog 教程]]></title>
    <url>%2F2018%2F10%2F24%2FHexoj%E5%BB%BA%E7%AB%99%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装及部署初始化1$ hexo init [folder] 新建文章1$ hexo new [layout] &lt;title&gt; 如果没有设置layout，默认使用config.yml中的defaultlayout参数代替。如果标题包含空格，请使用引号括起来。 生成静态网页1$ hexo generate 可以简写成1$ hexo g 启动服务1$ hexo server 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 部署首先，修改站点位置文件,文件位于项目根路径下_config.yml文件，1234deploy: type: git repo: "仓库路径" branch: master 这里注意:后一定要有一个空格，否则部署无反应。 然后，安装Hexo-git1$ npm install hexo-deployer-git --save 执行部署命令：1$ hexo deploy 该命令请在git中执行。 部署网站，可以简写为1$ hexo d 发布部署说明 hexo 分支:hexo笔记源代码 master 分支:hexo笔记访问分支 jekyll分支:之前博客文章备份源码文件夹一直处于hexo分支，直接修改博客，然后修改。源文件直接commit到hexo分支。部署直接git cmd使用123hexo cleanhexo ghexo d hexo已追踪文件及文件夹: .gitignore _config.yml source/ theme/next/_config.yml scaffolds/ 个性化配置更换主题 下载主题： 1$ git clone https://github.com/theme-next/hexo-theme-next themes/next 配置主题：修改站点默认主题 1theme: next 可以选择修改样式.打开主题配置文件(next/_config.yml)，选择以下即可：1234#scheme: Muse#scheme: Mistscheme: Pisces#scheme: Gemini 网站信息打开站点配置文件_config.yml，修改对应文字即可：1234567# Sitetitle: Hexosubtitle:description:author: John Doelanguage:timezone: Next的使用以后再调整 文章标签首先创建tag页面：1$ hexo new page tags 修改source/tags/index.md文件，添加type: &quot;tags&quot;：12345---title: tagsdate: 2018-10-24 21:25:58type: &quot;tags&quot;--- 修改模板文件scaffolds/post.md,添加一行’tags:’:1234567---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:categories:description:--- 给文章添加tags,在文章开头填写tags，格式如下：123tags: - Hexo - Github Page 文章分类同创建标签步骤基本一致，首先创建分类页面：1$ hexo new page categories 然后修改source/tags/index.md文件，添加type: &quot;tags&quot;：12345---title: tagsdate: 2018-10-24 21:25:58type: &quot;categories&quot;--- 最后在文章添加分类：123456789---title: Hexo教程date: 2018-10-24 18:14:18tags: - Hexo - Github Pagecategories: otherdescription: Hexo建站流程说明--- 阅读统计阅读次数统计（LeanCloud） 由 Doublemine 贡献请查看为NexT主题添加文章阅读量统计功能 文章搜索Hexo NexT 6.0+版本Algolia教程1.登陆注册Algolia,创建Index。详细步骤参考6.0以下或教程。2.安装1$ npm install --save hexo-algolia 3.修改站点配置文件: 12345algolia: applicationID: &apos;Application ID&apos; apiKey: &apos;Search-only API key&apos; indexName: &apos;indexName&apos; chunkSize: 5000 4.创建环境变量，Win下可直接手动创建。1234$ export HEXO_ALGOLIA_INDEXING_KEY=Search-Only API key # Use Git Bash# set HEXO_ALGOLIA_INDEXING_KEY=Search-Only API key # Use Windows command line$ hexo clean$ hexo algolia 完成后执行hexo algolia,得到结果：12345INFO [Algolia] Testing HEXO_ALGOLIA_INDEXING_KEY permissions.INFO Start processingINFO [Algolia] Identified 9 pages and posts to index.INFO [Algolia] Indexing chunk 1 of 1 (50 items each)INFO [Algolia] Indexing done. 5.安装依赖包。(可以选择修改CDN，参考教程)12$ cd themes/next$ git clone https://github.com/theme-next/theme-next-algolia-instant-search source/lib/algolia-instant-search 6.修改站点位置文件，启用搜索123456789# Algolia Searchalgolia_search: enable: true hits: per_page: 10 labels: input_placeholder: Search for Posts hits_empty: "We didn't find any results for the search: $&#123;query&#125;" hits_stats: "$&#123;hits&#125; results found in $&#123;time&#125; ms" 7.配置URL修改站点配置文件，将url设置为/(或域名),防止出现搜索结果跳转链接域名为http;//yoursite:1234567# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;#url: http://yoursite.comurl: /root: /permalink: :year/:month/:day/:title/permalink_defaults: Hexo NexT 6.0以下版本1.安装hexo-generator-searchdb：1$ npm install hexo-generator-searchdb --save 2.编辑站点配置文件,新增以下内容到任意位置：12345search: path: search.xml field: post format: html limit: 10000 3.编辑主题配置文件，启用本地搜索及Algolia功能：1234567local_search: enable: true...algolia_search: enable: true 4.启用Algolia：4.1创建APIKeyHEXO_ALGOLIA_INDEXING_KEY 进入Algolia的API Keys页面ALL API KEYS选项卡 创建APIKey Description：HEXO_ALGOLIA_INDEXING_KEY Indices：&lt;此处选择之前创建的Index&gt; ACL：Add records，Delete records，List indices，Delete index4.2设置环境变量HEXO_ALGOLIA_INDEXING_KEY,可手动添加1$ export HEXO_ALGOLIA_INDEXING_KEY=&lt;此处为第1步创建的APIKey&gt; 4.3修改站点配置文件，添加以下内容：123456# Add manual - algolia:algolia: applicationID: &apos;你的Application ID&apos; apiKey: &apos;你的Search-Only API Key&apos; indexName: &apos;输入刚才创建index name&apos; chunkSize: 5000 官方教程中未添加apikey列，导致可能失败。参考Github上教程 4.4安装模块12$ cd themes/next$ git clone https://github.com/theme-next/theme-next-algolia-instant-search source/lib/algolia-instant-search 4.5配置URL修改站点配置文件，将url设置为/,防止出现搜索结果跳转链接域名为http;//yoursite:1234567# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;#url: http://yoursite.comurl: /root: /permalink: :year/:month/:day/:title/permalink_defaults: 4.6执行Algolia命令123456$ hexo algoliaINFO [Algolia] Testing HEXO_ALGOLIA_INDEXING_KEY permissions.INFO Start processingINFO [Algolia] Identified 9 pages and posts to index.INFO [Algolia] Indexing chunk 1 of 1 (50 items each)INFO [Algolia] Indexing done. 文章公式首先卸载默认渲染器，如遇到错误可忽略。 1$ npm un hexo-renderer-marked --save 然后安装新的渲染器 1$ npm i hexo-renderer-kramed --save 修改主题配置文件,开启公式支持12345math: enable: true ... engine: mathjax #engine: katex 最后注意，在文章顶部为当前文章开启渲染支持123456---title: 文章名称date: 2018-10-24 18:14:18mathjax: true...--- Hexo文章公式使用注意 先写下标，再写上标，否则可能无法编译。X_1^2-$X^2_1$-$X_1^2$ {}的转义不是\{\}，而是\\{\\}: $\{\}$ 公式换行\\转义为\\\\: \begin{cases} 1 \\\\ 2 \\\\ 3 \\\\ \end{cases} 表头前要有一行空白，否则编译失败 * 需要转义为\*：$*$ &lt;t&gt;需要转义&lt;t\&gt;: $x^{}$ 请注意：mathjax的编译，请选择不同cdn。123456789101112## 底部标签 ##将文章底部的标签由`#`改为&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; 打开`/themes/next/layout/_macro/post.swig`，搜索`rel=&quot;tag&quot;&gt;#` 将`#`改为`&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;`## 谷歌收录 创建站点地图``` bash npm install hexo-generator-sitemap --save 在站点配置文件中添加以下内容： 12345# 自动生成sitemapsitemap: path: sitemap.xml #baidusitemap: #path: baidusitemap.xml 修改站点配置文件中的url： 1url: https://nocater.github.io 执行hexo d部署后，访问https://nocater.github.io/sitemap.xml，检查其中是否包含域名： 12345678&lt;urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"&gt; &lt;url&gt; &lt;loc&gt; https://nocater.github.io/2018/10/24/Hexoj%E5%BB%BA%E7%AB%99%E6%95%99%E7%A8%8B/ &lt;/loc&gt; &lt;lastmod&gt;2018-10-26T06:46:34.000Z&lt;/lastmod&gt; &lt;/url&gt;&lt;url&gt; 验证通过后，就可以开始配置Google了： 在谷歌搜索引擎入口提交博客网址 选择文件验证，下载html文件后，在源码里添加123---layout: false--- 禁止Hexo的模板渲染。部署成功并访问成功后，就可以通过验证了。 在站点地图提交sitemap.xml，并查看状态。 百度收录提交网址与提交链接实现与Google类似。不过站点地图可选择： 主动推送 自动推送 可直接修改主题配置文件，将baidu_push: false设置为ture。 sitemap(Google中使用此方法) 参考$e=mc^2$Hexo官方文档NexT官方教程]]></content>
      <categories>
        <category>other</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Github Page</tag>
      </tags>
  </entry>
</search>
